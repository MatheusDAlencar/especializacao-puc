{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO1gDYdaFugw1KLKy3OtKy9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MatheusDAlencar/especializacao-puc/blob/main/mvp_4_modelospkl.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MVP Identificador de Petição Inicial\n",
        "\n",
        "Este notebook documenta e executa todo o ciclo de criação de um modelo clássico de machine learning para classificar documentos jurídicos como “Petição Inicial\" ou não, usando um dataset real. O processo é transparente, modular e compatível com integração full stack. Todos os passos estarão explicados e justificados a seguir, facilitando a execução autônoma e a avaliação do trabalho.\n",
        "\n",
        "\n",
        "## Resolução do \"problema Petição Inicial\": por quê?\n",
        "\n",
        "O projeto se baseia em um projeto real que toquei ao longo de 2025. Trata-se de um classificador de documentos. Ele se faz necessário porque, em geral, os sistemas de processo judicial eletrônico sofrem muito com inputs de dados imprecisos dos usuários e um classificador de petições iniciais seria um primeiro passo muito importante visando o objetivo final de correção do problema apontado. Esse problema é particularmente importante porque ele é a causa da extrema dificuldade atual de planejar qualquer estruturação do Sistema de Justiça com base em dados, visando aumentar sua eficiência. Em síntese, as informações disponíveis não são confiáveis, uma vez que são extraídas dos sistemas de processo judicial eletrônico, mas eles são alimentados por usuários do mundo jurídico, que, na média, têm muito baixo cuidado com a precisão e qualidade dos dados que são inseridos nos sistemas.\n",
        "\n",
        "Isso leva a problemas como, por exemplo, não se saber exatamente quantos processos de cada matéria existem de fato, uma vez que isso dependeria de uma adequada classificação de classe e assunto de todos os processos conforme as tabelas processuais unificadas do CNJ (conferir em: <https://www.cnj.jus.br/sgt/consulta_publica_assuntos.php> e <https://www.cnj.jus.br/sgt/consulta_publica_classes.php>). Como isso não ocorre, fica-se sem saber a realidade do que se discute de fato no Judiciário.\n",
        "\n",
        "Para corrigir esse problema, seria necessário automatizar a reclassificação de classes e assuntos dos processos. Isso, contudo, traz outro problema anterior: quais documentos servem para reclassificar classe e assunto de um processo em andamento? Aí entra o papel do classificador de documentos. Em geral, o documento que delimita a classe e o assunto de um processo é a petição inicial, daí a importância de saber se um documento é ou não petição inicial, para, por meio dele, no futuro, encontrar a classe e o assunto de um processo judicial, permitindo a correção das bases de dados e diagnósticos mais precisos da realidade do Judiciário, viabilizando modelos de gestão baseados em evidências e, em última instância, a eficiência administrativa na prestação do serviço de Justiça aos cidadãos que mais necessitam da pronta e justa resposta judicial."
      ],
      "metadata": {
        "id": "VG5i_UFletlk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "## Iniciando o código ##\n",
        "## Imports necessários\n",
        "\n",
        "# Instalando bibliotecas que não estão aqui by default\n",
        "!pip install pytesseract pdf2image\n",
        "!sudo apt-get update\n",
        "!sudo apt-get install -y tesseract-ocr libtesseract-dev tesseract-ocr-por\n",
        "!sudo apt-get install -y poppler-utils\n",
        "\n",
        "# Outros imports\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import zipfile\n",
        "import joblib\n",
        "import os\n",
        "import pytesseract\n",
        "import glob\n",
        "import tqdm\n",
        "import re\n",
        "import numpy as np\n",
        "import traceback\n",
        "from pdf2image import convert_from_path\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from google.colab import drive\n",
        "from scipy.sparse import hstack, csr_matrix\n",
        "\n",
        "# Comentários sobre os imports\n",
        "# Foram escolhidas ferramentas de classificação e predição mais aderentes ao\n",
        "# problema enfrentado, em especial oscerizar PDFs para permitir a classificação.\n",
        "\n",
        "## Montando o Google Drive\n",
        "# Nesta etapa, montamos o Google Drive para acessar o dataset de documentos\n",
        "# classificados que vão formar nossa base de dados de treino e de testes.\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Eu autorizei o acesso do Colab ao meu Google Drive e isso pode ser pedido a\n",
        "# quem inspecionar este código também. Todavia, não precisa haver preocupação\n",
        "# quanto à origem da pasta dos dados, pois a pasta do meu Drive é pública e tem\n",
        "# até uma pasta extra com mais dados, que eu diminuí para deixar o modelo aqui\n",
        "# mais performático."
      ],
      "metadata": {
        "id": "SB37eKDRgD3v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d736388-6206-4a7e-8c41-0b2e91b78b33"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting pdf2image\n",
            "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (24.2)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (11.2.1)\n",
            "Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
            "Downloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: pytesseract, pdf2image\n",
            "Successfully installed pdf2image-1.17.0 pytesseract-0.3.13\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,804 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:10 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,080 kB]\n",
            "Get:11 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease [24.3 kB]\n",
            "Get:12 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,092 kB]\n",
            "Hit:13 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,566 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,262 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/multiverse amd64 Packages [48.5 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [4,763 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [4,917 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [56.4 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,404 kB]\n",
            "Get:21 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,752 kB]\n",
            "Get:22 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy/main amd64 Packages [51.0 kB]\n",
            "Fetched 33.2 MB in 4s (8,586 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.1.1-2.1build1).\n",
            "The following additional packages will be installed:\n",
            "  libarchive-dev libleptonica-dev\n",
            "The following NEW packages will be installed:\n",
            "  libarchive-dev libleptonica-dev libtesseract-dev tesseract-ocr-por\n",
            "0 upgraded, 4 newly installed, 0 to remove and 38 not upgraded.\n",
            "Need to get 4,600 kB of archives.\n",
            "After this operation, 18.0 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libarchive-dev amd64 3.6.0-1ubuntu1.5 [581 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libleptonica-dev amd64 1.82.0-3build1 [1,562 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libtesseract-dev amd64 4.1.1-2.1build1 [1,600 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-por all 1:4.00~git30-7274cfa-1.1 [856 kB]\n",
            "Fetched 4,600 kB in 1s (5,090 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 4.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libarchive-dev:amd64.\n",
            "(Reading database ... 126308 files and directories currently installed.)\n",
            "Preparing to unpack .../libarchive-dev_3.6.0-1ubuntu1.5_amd64.deb ...\n",
            "Unpacking libarchive-dev:amd64 (3.6.0-1ubuntu1.5) ...\n",
            "Selecting previously unselected package libleptonica-dev.\n",
            "Preparing to unpack .../libleptonica-dev_1.82.0-3build1_amd64.deb ...\n",
            "Unpacking libleptonica-dev (1.82.0-3build1) ...\n",
            "Selecting previously unselected package libtesseract-dev:amd64.\n",
            "Preparing to unpack .../libtesseract-dev_4.1.1-2.1build1_amd64.deb ...\n",
            "Unpacking libtesseract-dev:amd64 (4.1.1-2.1build1) ...\n",
            "Selecting previously unselected package tesseract-ocr-por.\n",
            "Preparing to unpack .../tesseract-ocr-por_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-por (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr-por (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up libleptonica-dev (1.82.0-3build1) ...\n",
            "Setting up libarchive-dev:amd64 (3.6.0-1ubuntu1.5) ...\n",
            "Setting up libtesseract-dev:amd64 (4.1.1-2.1build1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  poppler-utils\n",
            "0 upgraded, 1 newly installed, 0 to remove and 38 not upgraded.\n",
            "Need to get 186 kB of archives.\n",
            "After this operation, 697 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.8 [186 kB]\n",
            "Fetched 186 kB in 0s (397 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package poppler-utils.\n",
            "(Reading database ... 126445 files and directories currently installed.)\n",
            "Preparing to unpack .../poppler-utils_22.02.0-2ubuntu0.8_amd64.deb ...\n",
            "Unpacking poppler-utils (22.02.0-2ubuntu0.8) ...\n",
            "Setting up poppler-utils (22.02.0-2ubuntu0.8) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sobre o Dataset\n",
        "\n",
        "Como o Colab permite acessar um link do Drive público, montei uma pasta com documentos jurídicos classificados por mim. O dataset foi disponibilizado em (https://drive.google.com/drive/folders/1bhDT4BUMF2CjViTMBJpmNmMZ3dy6RXtU?usp=drive_link) e contém subpastas nomeadas com o tipo da peça jurídica. Cada pasta representa uma classe, facilitando o uso de aprendizado supervisionado clássico. O objetivo central é identificar, entre todos os documentos, quais são “Petição Inicial”, identificados dentro das pastas de nome \"PI\" dentro das pastas de processos.\n",
        "\n",
        "Exemplo de estrutura de diretórios:\n",
        "\n",
        "- Petição Inicial/\n",
        "- Contestação/\n",
        "- Réplica/\n",
        "- Outros/\n",
        "\n",
        "Cada pasta contém documentos PDF já classificados, mas montei o classificador de tal forma que permita também classificar arquivos JPG ou PNG, além do PDF, para que ele se torne, é claro, mais útil e de fácil uso.\n"
      ],
      "metadata": {
        "id": "CE4Lucn-g3LV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Leitura dos arquivos e preparação da base\n",
        "\n",
        "Aqui lemos todos os documentos do diretório extraído, associando o nome da pasta como rótulo (classe). Arquivos de texto são lidos diretamente, PDFs via pdf2image + OCR, imagens via OCR.\n",
        "\n",
        "A leitura se dá por meio do Loop de leitura das pastas e seus documentos. É muito importante que ocorra seu correto funcionamento, ou ficaremos sem os dados, impedindo o adequado funcionamento de basicamente tudo."
      ],
      "metadata": {
        "id": "AhB3vkOTrBsE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Para facilitar a estruturação dos dados, trouxe a pasta como .zip, então será\n",
        "# necessário extrair o zip\n",
        "\n",
        "zip_path = '/content/drive/MyDrive/Dataset_juridico/docs_classificados_2025-07-06.zip'\n",
        "extract_dir = '/content/docs_classificados'\n",
        "\n",
        "# Removendo o diretório de extração anterior para garantir uma extração limpa\n",
        "if os.path.exists(extract_dir):\n",
        "    import shutil\n",
        "    shutil.rmtree(extract_dir)\n",
        "os.makedirs(extract_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "# Coloquei vários trechos de código para me servirem como log, para saber o que\n",
        "# poderia dar problema e onde, porque o modelo é por si pesado e a extração dos\n",
        "# documentos demora muito, então eu não podia ficar travando a todo momento ou\n",
        "# tomando erro sem resposta.\n",
        "\n",
        "try:\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_dir)\n",
        "    print(f\"Arquivo ZIP extraído com sucesso para: {extract_dir}\")\n",
        "    # Verificar o conteúdo após a extração\n",
        "    print(\"\\nConteúdo do diretório extraído:\")\n",
        "    !ls -R {extract_dir}\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"Erro: Arquivo ZIP NÃO encontrado no caminho: {zip_path}\")\n",
        "    print(\"POR FAVOR, VERIFIQUE E CORRIJA O CAMINHO DO ARQUIVO ZIP NO SEU GOOGLE DRIVE NA LINHA 'zip_path = ...'\")\n",
        "    # Interromper a execução se o arquivo ZIP não for encontrado\n",
        "    raise\n",
        "except Exception as e:\n",
        "    print(f\"Ocorreu um erro durante a extração do ZIP: {e}\")\n",
        "    # Interromper a execução em caso de outros erros de extração\n",
        "    raise\n",
        "\n",
        "def extract_text_from_pdf(file_path):\n",
        "    try:\n",
        "        pages = convert_from_path(file_path, timeout=40)\n",
        "        text = \"\"\n",
        "        for page in pages:\n",
        "            text += pytesseract.image_to_string(page, lang='por', timeout=40)\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        print(f\"Erro na extração de texto do PDF {file_path}: {e}\")\n",
        "        # Imprimir o traceback completo para depuração\n",
        "        traceback.print_exc()\n",
        "        # Retornar uma string vazia em caso de erro\n",
        "        return \"\"\n",
        "\n",
        "def extract_text_from_image(file_path):\n",
        "    try:\n",
        "        from PIL import Image\n",
        "        img = Image.open(file_path)\n",
        "        text = pytesseract.image_to_string(img, lang='por', timeout=40)\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        print(f\"Erro na extração de texto da imagem {file_path}: {e}\")\n",
        "        # Imprimir o traceback completo para depuração\n",
        "        traceback.print_exc()\n",
        "        # Retornar uma string vazia em caso de erro\n",
        "        return \"\"\n",
        "\n",
        "data = []\n",
        "# Define o caminho para a pasta que contém as subpastas de classes. Sem isso, o\n",
        "# extrator não chega até os documentos necessários\n",
        "base_dir_for_classes = os.path.join(extract_dir, 'docs_classificados_2025-07-06')\n",
        "\n",
        "print(f\"\\nIniciando leitura de arquivos a partir de: {base_dir_for_classes}\")\n",
        "\n",
        "# Verifica se o diretório-base para as classes de documentos existe\n",
        "if not os.path.exists(base_dir_for_classes):\n",
        "    print(f\"Erro: O diretório base para as classes '{base_dir_for_classes}' não foi encontrado após a extração.\")\n",
        "    print(\"Por favor, verifique a estrutura do seu ZIP e o nome da pasta que contém as classes dentro dele.\")\n",
        "else:\n",
        "    # Itera sobre as pastas de classe de documentos dentro do diretório base\n",
        "    for class_dir_name in os.listdir(base_dir_for_classes):\n",
        "        class_path = os.path.join(base_dir_for_classes, class_dir_name)\n",
        "        # Verifica se o item é um diretório (que deve ser uma pasta de classe de documento)\n",
        "        if os.path.isdir(class_path):\n",
        "            print(f\"Processando pasta: {class_dir_name}\")\n",
        "            # Usando glob para encontrar arquivos com as extensões esperadas\n",
        "            file_patterns = ['*.pdf', '*.jpg', '*.jpeg', '*.png']\n",
        "            files_in_class_dir = []\n",
        "            for pattern in file_patterns:\n",
        "                files_in_class_dir.extend(glob.glob(os.path.join(class_path, pattern)))\n",
        "\n",
        "            if not files_in_class_dir:\n",
        "                 print(f\"  Aviso: Nenhum arquivo suportado encontrado na pasta {class_dir_name}. Pulando.\")\n",
        "                 continue # Pula para a próxima pasta se não encontrar arquivos\n",
        "\n",
        "            # Adiciona uma impressão para mostrar quantos arquivos foram encontrados na pasta\n",
        "            print(f\"  Encontrados {len(files_in_class_dir)} arquivos suportados.\")\n",
        "\n",
        "            for fpath in tqdm.tqdm(files_in_class_dir, desc=class_dir_name):\n",
        "                fname = os.path.basename(fpath) # Obtém o nome do caminho completo do arquivo\n",
        "\n",
        "                text = \"\" # Inicializa como texto vazio para cada arquivo\n",
        "                # print(f\"  Tentando extrair texto de: {fpath}\") #desabilitado para\n",
        "                # fins de performance, mas deixei aqui para o uso caso eu\n",
        "                # percebesse que essa parte estava dando erro\n",
        "\n",
        "                if fpath.lower().endswith('.pdf'):\n",
        "                    text = extract_text_from_pdf(fpath)\n",
        "                elif fpath.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    text = extract_text_from_image(fpath)\n",
        "\n",
        "                # Só adiciona se houver texto extraído (pelo menos 1 caracter após strip)\n",
        "                if text and text.strip():\n",
        "                     # print(f\"  Texto extraído (primeiros 50 chars): {text.strip()[:50]}...\")\n",
        "                     # Print de depuração, desabilitado para fins de performance\n",
        "                     # Desabilitação e manutenção no código por motivos idênticos\n",
        "                     # aos do comentário do bloco acima.\n",
        "                     data.append({'texto': text, 'classe': class_dir_name, 'arquivo': fname})\n",
        "                else:\n",
        "                    # A mensagem de erro detalhada já será impressa pelas funções de extração,\n",
        "                    # mas este print confirma que o arquivo foi processado e não retornou texto.\n",
        "                    # print(f\"  Aviso: Nenhum texto extraído ou texto vazio do arquivo {fpath}. Pulando.\")\n",
        "                    # Desabilitação e manutenção no código por motivos idênticos\n",
        "                    # aos dos comentários dos blocos acima.\n",
        "                    pass\n",
        "\n",
        "print(f\"\\nLeitura de arquivos concluída. Tamanho da lista de dados: {len(data)}\")\n",
        "print(\"Primeiros 5 itens na lista de dados:\")\n",
        "# Imprime os primeiros 5 itens, verificando se a lista não está vazia\n",
        "\n",
        "if data:\n",
        "    # Limita a impressão para não sobrecarregar a saída se os textos forem muito longos\n",
        "    for item in data[:5]:\n",
        "        print({k: (v if k != 'texto' else v[:100] + '...' if len(v) > 100 else v) for k, v in item.items()})\n",
        "else:\n",
        "    print(\"A lista de dados está vazia.\")\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "# Para garantir que o DataFrame só seja criado se data não estiver vazia,\n",
        "# ou avisar se for o caso de DataFrame vazio.\n",
        "if not df.empty:\n",
        "    # Não precisamos mais remover vazios aqui se já filtramos ao adicionar na lista 'data')\n",
        "    # df = df[df['texto'].str.strip().astype(bool)]\n",
        "    print(\"\\nDataFrame criado.\")\n",
        "    display(df.head())\n",
        "else:\n",
        "    print(\"\\nDataFrame vazio criado, pois a lista de dados estava vazia ou a extração de texto falhou para todos os arquivos.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "1qYxPeVgqc3O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1424b5ac-ded4-4fe1-e78a-0b47280ab603"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Arquivo ZIP extraído com sucesso para: /content/docs_classificados\n",
            "\n",
            "Conteúdo do diretório extraído:\n",
            "/content/docs_classificados:\n",
            "docs_classificados_2025-07-06\n",
            "\n",
            "/content/docs_classificados/docs_classificados_2025-07-06:\n",
            " Certidão\t\t\t  'Outras manifestações'\n",
            " Contestação\t\t\t   Outros\n",
            " Contrarrazões\t\t\t  'Outros pedidos'\n",
            " Decisão\t\t\t  'Outros pedidos (diversos)'\n",
            "'Declaração de hipossuficiência'   PI\n",
            " Despacho\t\t\t   Procuração\n",
            " GRERJ\t\t\t\t  'Recurso de apelação (recurso e razões)'\n",
            " Intimação\t\t\t   Réplica\n",
            " Mandados\t\t\t   Sentença\n",
            "'Ordem judicial'\t\t   Tréplica\n",
            "\n",
            "/content/docs_classificados/docs_classificados_2025-07-06/Certidão:\n",
            " 063d71ecdbc4a0eea1341cc039d2e81f315c9829.html\n",
            " 1abf44de4deaea92fcee45b3c6201785e1a6362a.html\n",
            " 1af516f03bce40e01c02b5b0122ecfaf9e1e5b5f.html\n",
            " 1cf89b091074fb56597752184743bdb8f304dadd.html\n",
            " 1daa29510dd80252744fd2628330954563b83315.html\n",
            " 1f4871428b8eee8079d85814be14d5c3ed311115.html\n",
            " 1f62cef855ee4f3361524b9f12b6cb9f4ce94f3d.html\n",
            " 20415008d0f702a115c230f52067fe3103183e05.html\n",
            " 23814dd8ec942b9cd07e6048142d74907f2ea4b8.html\n",
            " 2442ba3892ab646069b30e0c3a040efebac81aa4.html\n",
            " 28d5a782177716c502a990cb70a138718faa1c70.html\n",
            " 2aee0d6a9f0a47c760b7be4a6fbae047f693f379.html\n",
            " 304117d2e8eae5b4461fa32462a3ba9c5d92f828.html\n",
            " 336826df5a102cf8300231633d38d59822ba8a8b.html\n",
            " 3a222b5cb44d3e6d6224fe070a44a00cc4c41a43.html\n",
            " 3a5399d688d3797fe454b60b3a00d2fe7d797456.html\n",
            " 44d9bfc7ceba312995504500e07131eba0dc041f.html\n",
            " 4c36764ec060debbe6d6494dc9d42ef93907490d.html\n",
            " 4ddfc8867c849d2531383bda4421edf40fb7be1a.html\n",
            " 4e1eb35c98405a01a14fb959b271e778ddc40be5.html\n",
            "'4e8d6cb4f5f3ece99faddc76d229c1044900d472_certid_o de tr_nsito em julgado.pdf'\n",
            " 4ef8a2a5b0e10eda59d32998d79c724cce1447bf.html\n",
            " 4fc9207e15b0ad85ee47501d964d33675f3ce257.html\n",
            " 5bf6fc7ced746ae246ecf57d6d84ac23944c2652.html\n",
            " 64664f98a4a46923a9e89be57bc1793d97581d61.html\n",
            " 776b7d491761cf14997d7474251aa44fe2f95e49.html\n",
            " 7ea2fa9d585c29cab597d1155265e613a809d9da.html\n",
            " 832d29b7d6f022970c961af00950aa9b1f078f8d.html\n",
            " 8957041746eab033316348ecc6f2dfb67775b09a.html\n",
            " 9581f4737c8b41a440d179e9bd95a141af285c27.html\n",
            " 9a24a3c074cf2bad104185b8eb2b624d24acee0f.html\n",
            " 9c210f9ee1155e9eeaae08c8847c2d32ed2060d3.html\n",
            " a326ca6d4226f1543734a6dc4b34e36e540ec729.html\n",
            " a90429434855222ef974343ff70fc4b99e4fc6b1.html\n",
            " ae60dee66c4944da45399b067f860cea80e1b218.html\n",
            " b01e1f54074fe6c1b04efd7fa3419a4b77e700b0.html\n",
            " b31afd7f216a4866ec5d6af6373854cfef89159b.html\n",
            " b3536c9fb7e0c0a5a87ddf8abbf42bfe84bc4799.html\n",
            " b6f62c471ceb61c781ffd5d5cfdb3a2353cd4267.html\n",
            " b7d5ba2ad9ac44ef56b9d2762ad6946ed14ab7f4.html\n",
            " ba47a7acae3d54a4acf8dbcacd454c447415005b.html\n",
            " bb37fca0f9a98d81468b1c8fe7bd847b74f5d657.html\n",
            " c1173baa1d61e38ee50bdbd694cc851e03453db0.html\n",
            " c12536921070b02c0695e0b31a1a32740281e851.html\n",
            " c9775891968dbdf62824cb3b4cdf151a1c677c6d.html\n",
            " d026ba3dbc566ad585ae25bc9bd9fb7cc35c8fa6_CND_Fed_Maicon.pdf\n",
            " d804b9b00882d90d88b01cdb187b0bf1bfe39391.html\n",
            " e6406b532414d8d653a24a0f311d332d175b14df.html\n",
            " eb70b2a335b92b78160ba224186a9dd4aa36cdfc.html\n",
            " f07b6a0ece4f3239189c3043fbdf6ad3a315c69c.html\n",
            " f1550f09dd2a269947009a8702ced974480e27be.html\n",
            " f60fcd48c630580efee95b28057263986305914a.html\n",
            " faafa3191ab1bffbf918b4905db19be7f9abaefa.html\n",
            " ff4eefbbd756be71adc740319e55a8b6ec90923d.html\n",
            "\n",
            "/content/docs_classificados/docs_classificados_2025-07-06/Contestação:\n",
            "'458205549e4167e563d2a68038347da0a4074602_VALDICEIA BENTO DA SILVA-CONTESTA__O.pdf'\n",
            "'57f25ce013a83b98eec582cb89fd6c80875557be_TIM - Contesta__o MARIA DE LOURDES DE OLIVEIRA SOUZA PEREIRA.pdf'\n",
            "'5823a96ca2e77bcda7791475eee8f6a16ca1c9ef_Contesta__o - Jose Carlos Ferreira - Seguro.pdf'\n",
            "'618edddcf0d8073c9434d251cf2c10cc6bb84262_CONTESTA__O-JOS_ CARLOS FERREIRA DA SILVA.pdf'\n",
            "'788180ab9887e269043bbd31edb30e0eb0e38d0d_Embargos - Assinado.pdf'\n",
            "'904934a82d431645dff3adf0e75c86d2b1841373_0800035-12.2023.8.19.0067_CONTESTACAO_ROSEMERE DA SILVA.pdf'\n",
            "'ed42fbe079e073912acf78315b0f14228d247a21_FL_VIO PATRICK RAMOS DE SANTANA.pdf'\n",
            "\n",
            "/content/docs_classificados/docs_classificados_2025-07-06/Contrarrazões:\n",
            "61240a21a813470882cbc86f210e5e6ec7f3999f_CONTRARRAZ_ES.pdf\n",
            "\n",
            "/content/docs_classificados/docs_classificados_2025-07-06/Decisão:\n",
            "'0b23588ec6e59f383923d843686178c304101640_Deferimento J.Gratuita - 5_ Vara de Leopoldina-RJ - Abril.2022.pdf'\n",
            " 2d29bc7a9fc267bf80f7f6f63e6edda75ad96a7b.html\n",
            " 2d438f53817b9e8062be5312fcf79ad2e2a453dc.html\n",
            " 3af759dbc4b06510ee5e0abdb192c11392e75007.html\n",
            "'424e62308203d4502d9621eff414fa25befc4269_Deferimento Pg. ao Final - 47 Vara da Capital.pdf'\n",
            " 478ec75b4fa41541d3f46920a3afa83c0b4c9c35.html\n",
            " 50dae923cc0f8e40a218a690605af660fe3f521a.html\n",
            " 55d2f8063056aa73a65e4bf9fa07e992f8fd15d9.html\n",
            " 5b641d79d3863ead556e3a7e018ef9610f8c1b95.html\n",
            " 5d356591aae7c8caf3d046b448edc8135f2cd34d.html\n",
            " 63706afe50204e952211dceb0d3fb168f0c8fc5e.html\n",
            " 67d182a4771d039c32bff4a3dad8f8fa267f077f.html\n",
            " 777fc4e6fd8d70a61be4f49ed7a9a9918509dc6e.html\n",
            " 78ba0413437dc537ff15dc7e06df58a80e424108.html\n",
            " 81fc3dd72bf9c844205967978f2c75242312130d.html\n",
            " 872ad632b95432803081d084637f96c00f65f36b.html\n",
            " 903c7ff608e36f867065656729b23bcff829a14a.html\n",
            " a49ea5729a977072cf254cdc69c99d0f82d2b192.html\n",
            " d6215ce5fb31df3cd1bd1cc5f77ef79a4b55ac57.html\n",
            " df8e2b86cf219076e127fdbb09aa0ddf086c9ae0_Decis_o.pdf\n",
            " e0c213768b4d132140bf567ebddaa76044e4a06b.html\n",
            " ef6c0336849366cff82a9d37c5c91b0b03513ea6.html\n",
            "'f95bf8903da1bbcda8f9f0cbef03133803cbbfa1_Deferimento Pg ao Final - 1_ Vara de Cabo Frio - Fev.2022.pdf'\n",
            "\n",
            "'/content/docs_classificados/docs_classificados_2025-07-06/Declaração de hipossuficiência':\n",
            "'1da93796c50e14fb03c595e5837fbf4290d681b1_DECLARA__O DE HIPOSUFICI_NCIA - THIAGO FRAGA _1_.pdf'\n",
            "'283a722ba521b8fc12f1f287a3245bb39522e4ec_DECLARA__O DE HIPO.pdf'\n",
            "'30e29905d1022a7162f577aece883439d908c867_5- DECLARA__O DE HIPOS.pdf'\n",
            "'35c9104861fed91f12b9d9004f6e8d25a5499b10_5 - Declara__o de hipo.pdf'\n",
            " 664510055e2768f9fd835f0ae37b7be97f00b42c_5_DECLARA__O_DE_HIPOSSUFICI_NCIA.pdf\n",
            "'7847a9b84ba4468059f0612462eaa5e3537efb11_Doc.4 - Declara__o de hipo.pdf'\n",
            "'78efeca29ddf973d43cccecb6e1a0010aff023c2_03-Declara__o de Hipo Fl_vio.pdf'\n",
            "'9e5a793cf50727c2d10d48e5ce13ec97694564a6_003 - Declara__o de Hipossufici_ncia.pdf'\n",
            "\n",
            "/content/docs_classificados/docs_classificados_2025-07-06/Despacho:\n",
            " 02c634ebc2cd82a2448f08175285917463217ec9.html\n",
            " 1114d595663edd86145666b097d1768b2943dd71.html\n",
            " 1ad854f56f61c4adacab6aa0f99ef1996a67d264.html\n",
            "'1e41b633e1271f60a84ad2f7affa7f3b9be92db6_Deferimento J.Gratuita - 2_ Vara C_vel Araruama-RJ -  Mar.2022.pdf'\n",
            " 1ed56f66c719e1071f12adcede7622de248bf65c.html\n",
            " 20e54a8b82bf26b8ad1d90806e02d9b049f9c34e.html\n",
            " 2298a6b57d10912073a4423121637a344325552f.html\n",
            " 2f59d8426cf06973f21b3e0eed13d3ec9028d09f.html\n",
            " 35c211b52d0e0876415b557067e998acabcf3b61.html\n",
            " 4bea3c2ba2288a7a697d73edfeefb29dee4b4672.html\n",
            " 554b7434132cd5fa3771892dafec65f9a215d71e.html\n",
            "'55de59d77b72f200f8b8f57c75ee544510b1096f_Deferimento J. Gratuita - Vara de Maca_ - RJ.pdf'\n",
            " 58def57f431f76a71217f29bdf99c59f72687bd8.html\n",
            " 5bac5ba553a5bccaaaf97a5543b863017321799f.html\n",
            " 5f1455db807c706b857246f97da8fe00f5bdaca8.html\n",
            " 61482f45107c7dff6da6fc37e3639dc2e3759e2c.html\n",
            " 669d68c980b79f1c505a536bac714ad98858afcb.html\n",
            " 7c63225add473164e59a8f970cd8ad0b3c8977d8.html\n",
            "'8188a914c0e3d433594e563361b9640a228117f8_Deferimento J. Gratuita - Vara Unica de Quissam_-RJ - Nov.2021.pdf'\n",
            " 81ad7acf3eb9cec075c3b1fc0c3bf64ba68fd525.html\n",
            " 875068f988d04a58e5fc478a7fd3833793af9d4b.html\n",
            " 92cad188ea8ec9bd5932efe586f58e29366fe410.html\n",
            " 9bd964a0630e64ac3d4309b21eb75f0d7aa2c7ac.html\n",
            " 9c16fba9bb8a636b8f0fb4264e01193f7f058b8c.html\n",
            " 9fded776e6b90444601694f0b5e7e643c6fb5847.html\n",
            " a040e5d13527e8eb8bff5d405592d3133be3c453.html\n",
            " aa2c71785b9814255d69ddc0333dfc092ec1168c.html\n",
            " b4df68451499642c49a46b89aa10237d08e77742.html\n",
            " be75f2c132c52799491681b11de132af06b2ac2d.html\n",
            " c112ed4de55739614b7e0110afbcd90b881dd4c9.html\n",
            " c624430c0cdbc4f99788d17e2ba5e4bf8af05eb5.html\n",
            " ce2864a3e00b0872e8bf91c826c4de4df9abaa95.html\n",
            " cf301f10e1fb63bdbd3965adc3b91880cb78ccb1.html\n",
            "'d7f16097f77c2c457aa10c4bd528638977d56d5f_Deferimento J.Gratuita - 2_ Vara C_vel Rio das Ostras-RJ -  Mar.2022.pdf'\n",
            " d82b80e2493e87aec17b8a9ec5555a11d6035d47.html\n",
            " d84014b9b23ef1289d758f693803a235ef983acc.html\n",
            " db2bdc0332556f212b84ac6210667274e3ba84da.html\n",
            " e3a9e0de23de9c74886cad38d43d1fd646c116b1.html\n",
            " e558b488df08d7a2412b00888110998b9520684e.html\n",
            " ed6aa44763133efbb35f955e6be472bdbae9f3bf.html\n",
            " edb931fd4f79bd7bdb4d2a6c188cb0b5a10c0a4d.html\n",
            " f0541aaad95cea7ae7c839cd140b189f9f331b71.html\n",
            " f43d6501c2a8bbcba094b704c2bff3313a078ea8.html\n",
            " f5fce87cbdb7f37bb120a9bedc2deab903a1239e.html\n",
            " f86f886c936b42a7184a1068f44ebac61f7e7e1e.html\n",
            "'fd74fe90e4238d2a446e90d4dfd4930311026c2e_Deferimento J. Gratuita - 3_ Vara de Petr_polis-RJ - Mar.2022.pdf'\n",
            " ff33fe4385482b43008e1cb8231af3e9cb07da3f.html\n",
            "\n",
            "/content/docs_classificados/docs_classificados_2025-07-06/GRERJ:\n",
            " 013b466be59c375bf1fccec6eb8a3d24aba935c0_documentoProcessual.pdf\n",
            " 0469c5ea7a3b011ac6ec3cf3258254ee90caa888_documentoProcessual.pdf\n",
            " 0a1bf2c6064cebe354395b9acff633eb04b6395c_documentoProcessual.pdf\n",
            " 0fef0ba8965e997164a0be785ce740e4370953c1_documentoProcessual.pdf\n",
            "'2b8177f2c5921a9d36c24467e9abbd20b9c59aa4_12 DANIELE CONCEICAO DA ROCHA RJ.pdf'\n",
            "'3e2cc4cb58a6ba5a5511512d040edabe11ef61fb_GRERJ e Comprovante de pagamento - Assinado.pdf'\n",
            "'423d7b2e5c2047cdab2f8002fe9932758936332a_CIV 041885 22 - SISBAJUD R_25,02.pdf'\n",
            " 4cfde74954643161329aadae1edfb0aef003c13b_documentoProcessual.pdf\n",
            " 572dbfb94e393cfcf7a887a7e8dc2b4daa3f19a3_documentoProcessual.pdf\n",
            "'6433f7942aead202f20d5044a727fd4fb25ec8d7_CIV-041885 22 - SISBAJUD, RENAJUD E INFOJUD R_ 70,92.pdf'\n",
            " 698a8ce56ebddfa269f571e600494161ca73c880_documentoProcessual.pdf\n",
            " 6a601c0b48b4a54f4e2f691fe9a0f13c6633ceb1_pedro.caetano.grerj.diferen_a.pdf\n",
            "'6eea5c9075970153bcc6d33c9a81545d6b8bf032_3802523-02dw-4603855 - doc.pdf'\n",
            "'709e073bde41c7b604eecc8b7dd76338eac938cc_Guia_Custas iniciais.pdf'\n",
            "'9ee356147e01fbb78d704988bf899135eaf697b9_GUIA -  NIRLANDO.pdf'\n",
            "'a6bd963f3915878de7daa4b87e5bc45aa3900576_20037319906 NIRLANDO DE PAULA ALMEIDA GUIA IN _1_.pdf'\n",
            "'aef2cda576d76342a0c8202aefb5d688ff498858_Comprovante - NIRLANDO DE PAULA ALMEIDA.pdf'\n",
            " b1af1110f8afa3a94bf12dcb5b4a982c714b9b74_234105_Guia.pdf\n",
            " ba11947b0cc2a8f098a2f6697a432b0fcf79174b_documentoProcessual.pdf\n",
            "'bf82fb478c1538f35a033a3688c5791c34a6b02a_CIV-041885 22 - CUSTAS INICIAIS.pdf'\n",
            " c04c42ecaf9e92547b8e6ce74c3bdc359b3f2877_383601_234105_1.823_36.pdf\n",
            " c1c181265cbc6d21032b57e26e5dbade5be43132_Scanned-image_01-04-2025-174406.pdf\n",
            " c74f8917b10eedb06d0a6c2a864feb07ebab94e1_documentoProcessual.pdf\n",
            " cfceb8cb1c51dcb5a5b4e3e807e2a596b84f08d2_documentoProcessual.pdf\n",
            " dcad3900bf4a509572afc063df69ecdaed740c62_guia.pdf\n",
            " e0f3c95bc851e80bb62a22309ef2559aebe894e8_documentoProcessual.pdf\n",
            " f42eac305dc0b69e3950c35e275a0d855c255a83_inicial.pdf\n",
            "\n",
            "/content/docs_classificados/docs_classificados_2025-07-06/Intimação:\n",
            "149a5750e2508f550744406536bb25623faf2b55.html\n",
            "19fcfd9bf925ed4ec8b20462495246a234d30db4.html\n",
            "20ba0a7df2588296715f4f751212c693a3493570.html\n",
            "219075b13bfc9735b02fd02db19a78a9214dd3da.html\n",
            "2558912aa77a0190a426a0010e905bc75e31dfad.html\n",
            "28930665bacb3a8b490658a609938ec3d43281e4.html\n",
            "357330522498c22b607bbb56e740fbb4b93f8137.html\n",
            "3a1e4efb964ddc62a21b6a47fdd964ce7c4c02aa.html\n",
            "3abc2b9bd5d530a3823e73d7c0fc942ffe10387a.html\n",
            "4e3f413044b4d5a4421b494d1fde5093eafc0ed0.html\n",
            "57778d73cfe460bf82b9f774631f3b54d3949461.html\n",
            "658ba983aebe4e3d49c3dd3c676b3077de913cca.html\n",
            "67da7f2369f7cc589aabc00dba5e9f595045d80d.html\n",
            "6b8877f72ecf9c3384a1e7256ca7ca96ceb6522d.html\n",
            "76af1fb15992f268d73ea41d1394cd0dff2e9a1a.html\n",
            "83ba80cac454fac3146ecf0cb6685f2077b33661.html\n",
            "88db98e5c0cfa3f6bd3b806c79d12c273b59683f.html\n",
            "8ae84fe2a945ffe6891325f7fdebbb00283029a7.html\n",
            "8e8d6bd40b483d95f131625d5ec0295a300bad4a.html\n",
            "93f7daea8de21eaafd689b16ccdba7c938f0185f.html\n",
            "a406a5c257488ab7cb3da5476c258b1beb523756.html\n",
            "c07af6153ce4c192433d815bbfe82b0288688283.html\n",
            "c5b9f74084c9ce9dcabdd3938ad33111936330bd.html\n",
            "d0e3bc84f96824ed73764b18bfd58cb4186a9aee.html\n",
            "d582b368d774991a771821c23b8b6105e382b563.html\n",
            "dec8b64a4000f8e0ffc4d51ba286938a0f7f56eb.html\n",
            "e3009dd8315f26624d50b7b19b400e350abe7dc0.html\n",
            "f5eba7f4818a1cef562ba438016d848a04f94a92.html\n",
            "f63304bdc90ba842a44fc79dfa5d32142f4c9d38.html\n",
            "\n",
            "/content/docs_classificados/docs_classificados_2025-07-06/Mandados:\n",
            " 0b5e5372a2b734a4956bc3f28606f56b9092733d.html\n",
            " 0f0dee523987a338ed94a9db2b481d90dbf0b69f.html\n",
            "'112cf75aa189d3d57f4227ed2a99af4dccdecde7_DANIEL BASTOS PJE.pdf'\n",
            " 136d3991dfb98d00da93e46a7cff0cb1cb7c4f87.html\n",
            " 19a5d59488f2e685612f63547c86ee66bc4c65b8.html\n",
            " 2170796bdec55fbdaeb4662121fe84c4290d431c.html\n",
            " 27bbd1d504b6ac05e708d54809e71ceebf511191.html\n",
            " 2ae7c4146614c27f6e0ccb3b66f809390f105c0e.html\n",
            " 2cb14d48aa93a2f661df75b03c72006b6846d3af.html\n",
            " 391908cb15d3f63dc408ad3395353acbdf8e9d7b.html\n",
            " 504501a40dd5b833ffc47f8273ce3acda990e114.html\n",
            " 693ad3e9962ccf64b8efbad0de250a664bc8dc37.html\n",
            " 6bd61107f06c5c50ba0ce2f224f5248556d18a6b.html\n",
            " 6c725b5cc0ee81f6c8240443fd2bb12a230274f2_aaaa123_1719.pdf\n",
            " 6faee791676bd3cf360599bacb642787e3fa7dbe.html\n",
            "'7b3d815b45e95872c2b6fd7748c3f275526e9052_DANIEL DE SOUZA BASTOS PJE.pdf'\n",
            " 7fd2daa85c241a8e2e342a158e9095451c08e6b6.html\n",
            " 87f27cd2c79145e843f59be6e085db6622d253a4.html\n",
            " 8d896185c3afb5820ae21f87d026cdc5760c8463.html\n",
            " 950e4546923e22474af23d3c533dae8745c51512.html\n",
            " 956ba642ac758c5dfd0c9a7e70e4ca28d86e5614.html\n",
            " aeb59802df25e01aa8967e0744806db6ee3a6b98.html\n",
            " b693b89d5b751d1fdc53d86027be20c76a7be247.html\n",
            "'c940bb4ed642faaea9a4cab2ae8a4da7fd0afa49_mandado pje LBR.pdf'\n",
            " d63828e95210d9fa94c64c8aad50cc816ce30682.html\n",
            " d6a1a182e467e4a26a213512eecce7b96fcf8342.html\n",
            " da467cfd7b8289f17205ba5209fcccb12b82e6e0.html\n",
            " f528e7c87f7fc10e03f680f8e7a0436c05846c51.html\n",
            " f77fc08ca0f933dab8c8fe60055f574b988c8412.html\n",
            "\n",
            "'/content/docs_classificados/docs_classificados_2025-07-06/Ordem judicial':\n",
            "f60700e216aa94424b790817d7b707c9f03fe6cd.html\n",
            "\n",
            "'/content/docs_classificados/docs_classificados_2025-07-06/Outras manifestações':\n",
            "'04864963fd98dc7c7e9324f3f5adf259e6f233ec_Peti__o - JOSE CARLOS FERREIRA DA SILVA.pdf'\n",
            " 1f7a02e67da3e1fdbb3b99d6eedecc15e263e47d_Manifesta__o.pdf\n",
            "'1fc40d1e9375303935d1b5304fc9a8eaedfc6cbf_JUNTADA DE SUBSTABELECIMENTO - NIAZEIS OLIVEIRA BISPO.pdf'\n",
            " 587ad3e7daf5c3a96a1783a3b415e0b18961377a.html\n",
            "'5ed240f4ea96c664fdd541dd3b186657650f1c2a_informando erro no sistema PJE.pdf'\n",
            " 5ed33afc995296a4d1394cc2fa1b36cc58951932_Manifesta__o.pdf\n",
            "'860356d402084919411e786bd07cbdbb4d98b5f0_VALDICEIA BENTO DA SILVA.pdf'\n",
            " 872a1099d6a548f3e2ed68e335be0759c1c3eee8.html\n",
            " 98f9481a53a7439fb7e28e90fb126ae6cdf69fe8.html\n",
            "'9a683379d68293c853dac993d4351d79ee81096f_MANIFESTA__O JOS_ 0800204-76.2023.8.19.0009.pdf'\n",
            "'a5c3e28c755bc30cb0fd2b35b86630d819955943_Peti__o - Juntada de comprovantes.pdf'\n",
            "'b2991e72d2fe9ec81831ccd700fd981d718c27ce_JOSE CARLOS FERREIRA DA SILVA-peti__o.pdf'\n",
            " b65ba99f54b190a650c465622de964a2145fc4ed.html\n",
            " cbe0984e9d5b0a0e8453c7c2298c85d062eedc06.html\n",
            "'d071475e01940d9086a2773c775a98a8de099354_juntando GRERJ taxa judiciaria.pdf'\n",
            "'dd50e43dde8127121a61b78496d1771d2479d033_AR4 X ROSEMERE DA SILVA.pdf'\n",
            "'e3875a3bb3a69976e489ce506386a3cca20ef190_PETI__O PROVAS.pdf'\n",
            "'e416d0d94ce15522b01dec63493217e1d8d79626_MANIFESTA__O JOS_ 0800210-83.2023.8.19.0009.pdf'\n",
            "\n",
            "/content/docs_classificados/docs_classificados_2025-07-06/Outros:\n",
            " 00ef221c649d14801ac0229de1a66d0f7d8e09c2_384381_526617.pdf\n",
            "'0114c700d553bdd193b99a27e909c4436f978e1d_9 GRAVAME.pdf'\n",
            "'02eccfbed2f05fb79ddf15cded4d835c484e4fd8_Receita Federal do Brasil 2022.pdf'\n",
            "'0562f6993fd13e43da38204f90c39ca566e6b635_Comprovante de Libera_ao de Cr_dito_pdf.PDF.pdf'\n",
            "'0645fc09449f402a5d199a669a0a64740df8ef68_8-SCPC - CONSULTA ATUALIZADA.pdf'\n",
            "'0f9af83f1f4d3a54f1c010e98957625b8c61f6df_Doc. 07 - Protesto_compressed - Assinado.pdf'\n",
            "'116713374f8c00b8602c00d85e47ff28de6e7c11_Receita Federal do Brasil 2021.pdf'\n",
            "'15bcd4c92bace348e5442a54f027fdceb4e68908_Consulta restitui__o IRPF - N_o Declarante 2021.pdf'\n",
            "'1a58a54951bdd59aae4c1f1c9d21e183c9afa1b2_Doc. 06 - Canhoto Assinado - Assinado.pdf'\n",
            "'206251670a1ae1904d68efcabf75f329541a2216_ATOS_PROCURA__O_SUBSTABELECIMENTO - 04.05.2021.pdf'\n",
            "'278af285f3a71b6351af99a052c0c7b97352a828_Doc. 11 - Planilha de c_lculo.pdf'\n",
            "'285240012a2506e86a31d25fbc3f661911588914_Doc. 09 - Boletos.pdf'\n",
            "'2a0c0ba1fe0dc759b8308b89e52491426c4ef904_PLANILHA DEBITO.pdf'\n",
            " 2c513e1b2b82682bd11a0c89b787dec907d83d56_EXTRATO_21985687446_010323_300323.pdf\n",
            " 2d24fdf690f1211c500374174a2254b09df83252_3_DOCUMENTO_DE_IDENTIDADE.pdf\n",
            "'3041ec02de90490f884199b0eb6b09b54a842353_14 - SEGURO CART_O 4,16 6.pdf'\n",
            "'3ad6794fb2d44c9831860bb7f322a1e78c2e0e26_Doc. 03 - Ata de AGO 13.06.2017.pdf'\n",
            "'3d87d04aedad87a3a8ceaebbc10ceea37fe5ac59_Doc. 05 - Ato do Presidente n_ 1.349.pdf'\n",
            "'4c5c5a72e62ddbf35cd08f7a1eb7dec5f23e2c0b_ATA de Assembleia.pdf'\n",
            " 4f7c6f3442f59a150a4c83d86488f1d62b2759d8_234105_Comprovante.pdf\n",
            "'5f58c6ed5cc9ee6d045d9b4d0bf7a8aceffad8d5_3 - Comprovante de residencia.pdf'\n",
            "'633ca34aaa2c07631fbde7ad49d391131cc652fc_10-RELAT_RIO GS04.pdf'\n",
            "'6591b6636a86d34b1455baa2e478ce98fb99a88c_Doc. 01 - Contrato Social - Assinado.pdf'\n",
            "'666c3c8570c68234b0002d9bcefd3699cdda2e00_REGISTRO - KATIA _1_.pdf'\n",
            "'6b3af604f27e190c9e5a7ae953e899e33e7589b4_Fl_vio TOI 9793549.pdf'\n",
            "'6fbd37f88f34caa6995276b9dabad145c55ecea8_Doc. 06 - Comunicado n_ 35.173 de 13_2_2020 dacasa.pdf'\n",
            " 831d215b447d4c5d30d9dd458155f98fdb98c95f_DD026211-91C2-4BB9-871D-60BBAC73539A.pdf\n",
            " 888e5c2ac36986150709247475bb1cb9691641b9_RECIBO..pdf\n",
            "'8bf3942edf50e9246bd50ff92da1be915a32dea0_ATA BANCO J SAFRA _1_.pdf'\n",
            "'9c528973ee0293e73ea5930afc740b13c5865f5d_COMPROVANTE DE RESID_NCIA.pdf'\n",
            "'9fefc6bef1a1dbc9b0bb4c1a1f39bc15333bc213_Consulta restitui__o IRPF - N_o Declarante 2022.pdf'\n",
            "'a3c05b15c4803dcacdce6ae6c6b03b30a4d30b2a_8 - ISENTO DE IMPOSTO D ERENDA.pdf'\n",
            "'a3c7ca0552a5a34247c47ee0857c527b301172e3_Relat_rio SCR.pdf'\n",
            "'b767cb6d8755eb5c7476d8802943dedfbff90dce_05-IRPF 2021.pdf'\n",
            "'bbdb4b712a483b0a4415f9ea2a5aff7f671f16fe_6 CONTRATO E ADITIVO.pdf'\n",
            "'c442a0da128e5548e0096e0872708a51a7c977ed_7-SERASA - CONSULTA BAIXADOS.pdf'\n",
            "'c57b4824fdb12e92c4ae9bbdef1842c074921593_0800871 - COMPROVANTE DE ENVIO.pdf'\n",
            "'c6251f767e410ef962fe05a49a7ee2f7d0e307ca_Estatuto Social_Cia Sa_de.pdf'\n",
            "'c6cfe053c5d861386fdb95b9326a45ea4c1f752b_PROCURA__O SAFRA_.pdf'\n",
            "'c759cf161487cec1808dd6a63858110fb2d43aca_7 NOT.pdf'\n",
            "'c9ac317aeeead902f2d0bb96fa44e8de09e6629a_7 - Certidao-NEGATIVA.pdf'\n",
            "'d0be6e8aa6710ed9e4982d35b77b674ad2216b7c_2.Procura__o 2022.pdf'\n",
            "'d3193040189b4697d8de52270d949ed2b86e4c19_Receita Federal do Brasil 2020.pdf'\n",
            "'d4d2089fe67a32130efa50d8d607033a5c96a93e_06-IRPF 2022.pdf'\n",
            "'da24677e1802d272614779df8b218f19d9cbc821_12 - C_LCULOS JOS_ SEGURO CART_O 4,76.pdf'\n",
            "'dd936199afb6fc5fc3938a157ceb2dd93f65715d_11 Parcelas Reneg 2022.pdf'\n",
            "'ddaa09a5a3d90dbc9d635a97bc06a57cd557c26d_Consulta restitui__o IRPF - N_o Declarante 2023.pdf'\n",
            "'e2a1308fcda1e4bd47bff2a789661434e9da5d37_1 Proc2023  076844  Banco Santander BRASIL SA e outras.pdf'\n",
            "'e6272abddefcd66d4661f5bc8202f451266589b4_kit 2.pdf'\n",
            "'eb82e0d447c57bf438a978f68019084fc216e775_Extrato SERASA.pdf'\n",
            "'ed0a9da24da4a73c439a4082e39ba1cb2959ec9b_7.TELA SNG.pdf'\n",
            " ede4588e340b4871b1bb62334a5964407643c2a3_4_COMPROVANTE_DE_ENDERE_O.pdf\n",
            "'f0e31eb322c44665941e3e9d176c2268caa194d9_2 Subs Aymore 2023  MAC BARBOSA SOCIEDADE INDIVIDUAL DE ADVOCACIA.pdf'\n",
            "'f22c4de9ff23f266842a30a3e2550c159c46439e_CONSUMO SITE R_.pdf'\n",
            "'fac3e98bebfcb27be1af4a6ef86d017b5e769d84_04-IRPF 2020.pdf'\n",
            "'fb429e9292e0dc8e6703d1c18ab769e0aec3dc75_Contrato Empr_stimo Ita__.pdf'\n",
            " fd5adb876b29dbe85db20d2c5760284d95f034f1_E-MAILS.pdf\n",
            "\n",
            "'/content/docs_classificados/docs_classificados_2025-07-06/Outros pedidos':\n",
            "'019627f1ebdf40798830dd02a0759b0b18cd7a50_Pet. Representa__o - 0800204-76.2023.8.19.0009.pdf'\n",
            "'2cbdb14a1f5f5c522a8e5014952060726352c496_Especifica__o de Provas - AIJ - JOSE CARLOS FERREIRA DA SILVA.pdf'\n",
            "'53d938f5b0a90683c218ea5ce1e2cb6a6e1b9726_MENIFESTA__O AUDIENCIA 0800204- 76.2023.8.19.0009.pdf'\n",
            "'c211aa636e1507126f6bc6e99f12dcd72978cdcf_1-Peticao de Juntada - Carta de preposicao e subs.pdf'\n",
            "'cacacd755e7fa120beff360f1be25805172445a3_PRODU__O DE PROVAS -JOSE CARLOS FERREIRA DA SILVA.pdf'\n",
            "\n",
            "'/content/docs_classificados/docs_classificados_2025-07-06/Outros pedidos (diversos)':\n",
            " 02348d0276b8a80ebeab489b2444aeff2ec8d36d_234105_GEN_RICA.pdf\n",
            " 02e2b0cf5214d6a563781f1f212faf89358e723a_Peticao1728497452eve8160445.pdf\n",
            "'055251d5197ce52f90b8170be42300fff46bf12d_MENIFESTA__O AUDIENCIA 0800210- 83.2023.8.19.0009.pdf'\n",
            "'065476d5ac3dccf6cf6754978ad2d4d182ea4693_Carlos Henrique Fraga  - Peti__o Intercorrente.pdf'\n",
            "'0665770a698ffab7e16239ce0e4ab33f56695488_Rede Manaus x LBR Loca__o - Informa recolhimento de custas.pdf'\n",
            " 06a62346b680dd63d6ab405440cf1cc426f68330_Homologacao_do_Acordo_assinado.pdf\n",
            "'11827d1165db56af1dd7001b3318aa4a39d2ca48_Manifesta__o -JOSE CARLOS FERREIRA DA SILVA .pdf'\n",
            "'12526e1bbc84bd7e25355f837ab11d353434845e_PETI__O - reiterando o pedido retro ou feito.pdf'\n",
            "'1a01853b165bd45b1e532a6af4e185431ba74868_PROCURA__O COM HABILITA__O.pdf'\n",
            " 1b0ea8dc15b50beb515c84f696faf528305abc6d_Quitacao_-_Assinado_assinado.pdf\n",
            "'27d9cb9ec05f59dbadef39da89a6578a12a9a5a6_DANIELE CONCEICAO DA ROCHA - PETI__O.pdf'\n",
            "'28f8386cc09b5e8622cc69ed36eb6e14e5469ad9_Manifesta__o - Requerer Publica__o da Ata de Audi_ncia.pdf'\n",
            "'2e9315beb8b329270dbbd20be4f4d31737555ade_11664927_MINUTA DE ACORDO - JANETE RITA VALENTIM LUCCAS.PDF.pdf'\n",
            " 2ee24cbbd7c239bd23e342d15a184dc8a2920df1_PETICAO.pdf\n",
            "'35306fb59664657e8a3deed98aea6ae5b89eaece_3802523-01dw-4603855 - juntada custas complementares inicial bap.pdf'\n",
            "'3c2871b114110747388ca54f7cae3e264a1b4c7b_7861512-01dw-exmo 1_organized-411.pdf'\n",
            "'3d82bd403b17b9fe23a8be0f9d736a4afc11a1a7_MANIFESTA__O -JOS_ CARLOS FERREIRA DA SILVA .pdf'\n",
            " 3ea23089542e033e2718091ee5ca49fa8e705a39_8315344-01dw-petiohabilitao.pdf\n",
            "'4486449f7cab80ba61b86467d9e1add9b7a7be3f_PETI__O COMPROVA__O DE CUSTAS -OSVALDO LUIZ PINTO.pdf'\n",
            " 4c450c94abe70744bc0d426b2a2e95cb321a37d1_13513706-01dw-exemplopetiomodelodwlaw.pdf\n",
            "'4fe6ec3727c34b78591ad61667b47839b6d23990_requerendo cita__o.pdf'\n",
            "'515856771acb73d369b139df55c74a84e29499b1_9113317-01dw-4603855_petio requerendo desbloqueio do veculo.pdf'\n",
            " 5404ac01ade8199cb8b4ff5a7c0b1ec1bfd89e7a.html\n",
            "'543d9eef22a31cbb82d9849c024c365f708c2b9b_OSVALDO LUIZ PINTO - requer sisbajud teimosinha.pdf'\n",
            "'563b12f90b39cab05ad228e2ae10b71ee46f2358_PETI__O TUTELA DESCUMPRIDA.pdf'\n",
            " 5a7ab430e37bfe4b6c4f967f468469156bdbf2f8_11703122_PETI__O_39829650.pdf\n",
            "'5ac555dafa0631670adff022c3429a7279358086_VALDICEA BENTO DA SILVA CONCEICAO.pdf'\n",
            "'6634612999e5c0042226be71af1fcf2fc1828948_Peticao de Juntada - Carta de preposicao e subs.pdf'\n",
            " 6750506a96502e63668a3572e4188e68ac1ccf6e.html\n",
            "'67a2c5030a78bcfac39b2919259f9a7a07fadb6d_PETI__O DE JUNTADA - NIRLANDO DE PAULA ALMEIDA.pdf'\n",
            "'68c4cc7c8cd418307dac0712d40dbe4413a3b649_RJ - DANIELE CONCEICAO DA ROCHA.pdf'\n",
            "'6a0e3789f0fa892f4c3724876d3aff1f715c6dd5_EXPEDI_AO DE MANDADO - NIRLANDO DE PAULA ALMEIDA.pdf'\n",
            "'7443bbb8560e4cd9e11f1db4417fcfa3ff0c7734_PET. CUMPRIMENTO DO ACORDO 4.pdf'\n",
            "'84582f285e65d709c9b8db3cc10d8cd33795680f_peti__o custas.pdf'\n",
            "'84877a4db157b71bd1aa0f5080877edb6130594b_requerendo senten_a.pdf'\n",
            "'86ef930e5a73de4976228ca1e35119c721d7cbb4_reiterando peti__o.pdf'\n",
            " a9166e0c63fc5d20571e8cae96b99598698a8b01_234105_DESIST_NCIA_DA_A__O.pdf\n",
            " aeb8b7f7b3ebedab06990174f1aaf94f7f4bd739.html\n",
            " b5b5dcc11c7ae0fe274a0f0a93b42f3ef961f5d0_peti__o.pdf\n",
            "'b98a69f686f2342da2fd8b59b7f56487da11f5f6_Peticao provas.pdf'\n",
            "'bd73238e6c3fd823f1b1956e82e2f0ac0abff482_Pet. pedido de penhora - 0800139-91.2023.8.19.0038.pdf'\n",
            "'c00558535cc2cd32f237083da3500518ccb77cd6_Peti__o - penhora 22.01.24.pdf'\n",
            "'c1cafb99b7153e5de03676444a870e6c98d18431_PETI__O APELA__O.pdf'\n",
            "'c7c773619a6ec16d91a6dde0ef83a565b9b3b4db_VALDICEA BENTO DA SILVA CONCEICAO.pdf'\n",
            "'cd69c121f9b7117b0d80d5bba6b594a7241b7971_Expedi__o MPG.pdf'\n",
            " d329993cf3769432a741c836ae956aae5bde7a6d.html\n",
            "'d33416cb1da5bb7f827164105a9cb1a7b430fd94_PET - NIRLANDO DE PAULA ALMEIDA - SUBS RIO.pdf'\n",
            "'d9b7f9bd8bf55c97a5a02f6911df92db055004bf_requerendo cita__o s_cios.pdf'\n",
            "'df239613257fcca0e5534793ded208950ea2cb5c_ROSEMERE DA SILVA - ESPECIFICA__O DE PROVAS.pdf'\n",
            "'e02deb509efb6a6f2b966c40947eee7315882c67_JUNTADA DE SUBS.pdf'\n",
            " e146eb3913052e749fd0728a0bcdfedc44fdc63f.html\n",
            "'e2b5a0a8dd645f19fa9232da618c683c5f896baa_PETI__O NIRLANDO.pdf'\n",
            "'e7d3a7f3a4bed4d2ae1a3fe478f8d71bc7ecd861_Peti__o Prosseguimento da A__o - Maicon Ferreira.pdf'\n",
            "'e864f9a0f633ec9115718800e27b7c1abbf165f1_PETI__O - Penhora online SISBAJUD.pdf'\n",
            "'ef3568a6140357653b8b89a4ae9d408736765731_ROSEMERE DA SILVA HABILITA__O.pdf'\n",
            "'f2c6daae1c630b6102f6a63802fe663bc7cfba5a_Manifesta__o Gratuidade - 0800610-82.2023.8.19.0014 _1_.pdf'\n",
            "'f81e3249a7a58cefbd44061c578deff95a8f8e7b_Pet. Representa__o - 0800210-83.2023.8.19.0009.pdf'\n",
            " ffb292fbadb49a6a059e42d4e89bb3e61cb4490d.html\n",
            "\n",
            "/content/docs_classificados/docs_classificados_2025-07-06/PI:\n",
            " 019d52168559a800b206b4048308784540c7c272_inicial.pdf\n",
            "'151dea44e675efef1fa803f99537d1af98d22379_Peti__o Inicial - Maicon vf.pdf'\n",
            "'2fb539e8e4a363c92db3d4181e23b59b1d4a6a62_PROCESSO_ 0800181-34.2022.8.19.0020 - MONIT_RIA.pdf'\n",
            "'4c240afa4a8878d4be8114c303cee4065bdbc713_1 - PETI__O INICIAL JOS_ SEGURO CART_O 4,16.pdf'\n",
            " 4ce9fafd7900125445637e180995684bb7606d3e.html\n",
            "'5e7f9c8f52fafec35bd3bef72cfc154dde287043_OSVALDO LUIZ PINTO - 38.302429-4.pdf'\n",
            " 5eb62ddefed839916dedb5b32173389397d4564b.html\n",
            "'62ef6e76863d96425ab8cef93304262e134090b1_1 - PETI__O INICIAL JOS_ SEGURO CART_O 4,76.pdf'\n",
            " 647fe8924d6a26dceafdb0d4bbbbfbeb8bab92b7_pedro.caetano.processo.despejo.pdf\n",
            "'6cebef1ba51cc2c2c994bbb63fa19e8ab57f593c_Inicial - LBR LOCACAO- Assinado.pdf'\n",
            "'72cec3d885669ad7d344c3935c2cf8a98456cdd9_Peti__o Inicial.pdf'\n",
            "'7b61262f570b5a3d54eaa2d655b6b124e7a60382_PETI__O THIAGO.pdf'\n",
            "'80fc5ef509dfa0e354a9d945807fb418c2eac573_1 Inicial.pdf'\n",
            "'8cc2e7b9f210315920971dce316f6ca4530510c6_1 - Peti__o Inicial.pdf'\n",
            "'8d1d780b46e942eb2473916212b2bd9ad23e46ca_Peti__o Inicial _3_.pdf'\n",
            "'8ead76d392d10d9efc5dfdf07d90e93b9c3fa3ce_A__o de Execu__o - Pr_mios _1_.pdf'\n",
            "'954d579321eb1de2b2a80eee35b7b40927ea8858_00-Fl_vio Patrick x Light.pdf'\n",
            " 9a2ff0fbd54d85eb404a180cf695d2c5362227c9_1.INICIAL.pdf\n",
            "'9a827c5c6d87609a8e3d03269bc6980597f52e96_1 INICIAL.pdf'\n",
            " 9debea50de6ecc4c247e6e080cd72b7cc735a089_INICIAL.pdf\n",
            " a6e3fd573ad0d10cb769e4a6cd29ed3d247c546f_peti__o.pdf\n",
            "'d02dba1a9b0f7286b0be7323d699f0957d325169_Peti__o Inicial - Assinado.pdf'\n",
            "'d41a2e5496f885c81292c82a8cbcc721ddb80f11_CARLOS HENRIQUE FRAGA - Assinado.pdf'\n",
            " d9e15f70dd2dd567fd2a288bbeb07b78c79072f2_inicial.pdf\n",
            "'df50060572d5fd2e11b59377ad0ef0b7406583e2_001 - Inicial.pdf'\n",
            "\n",
            "/content/docs_classificados/docs_classificados_2025-07-06/Procuração:\n",
            "'040d51dad9855a4c9ee1b46948488cb739f7bf27_13513706-06dw-banco e bbv - subs.pdf'\n",
            " 0696cb85810f6233e7ed553e65970dde34bacb41_8315344-05dw-substabelecimento.pdf\n",
            " 0dc7c4e9f0b04ca7995f826d1bbe359a224ebb93_SUBS.pdf\n",
            "'103f59085c430a5ddde24d76b451b75a31c12027_FIES DEPOSITARIOS AYMORE-  RJ.pdf'\n",
            " 120035f646159695b8b04b1eb991ad9eedbbe1a8_2_PROCURA__O_AD_JUDICIA.pdf\n",
            "'17e88de51b239835a27218d4b1be86d6116a6be0_SUBS SEM RESERVAS DACASA NAVIA.pdf'\n",
            "'189d2986d8b13d86cd60973c84d8864dd1542aee_Doc. 01 - Procura__o 2023.pdf'\n",
            "'1cb22c4d32579af762acef22b7288647ad2fb7c7_002 - Procura__o.pdf'\n",
            " 1db6af48f1109a585582ca00c8877d0d1bb291d7_SUBSTABELECIMENTO.pdf\n",
            " 1dce97717bc5bc1df6da231af3a00fd4c3a29969_3-SUBSTABELECIMENTO.pdf\n",
            "'1ea2e23342d36b8f5ca86f0dd809f807fa3dad7d_4 substabelecimento interno-2.pdf'\n",
            " 26d2e60ad898cd5afa67ded6a24011896fd749b4_procura__o.pdf\n",
            "'270e33994572f583fe53b8afd523436c48dc3771_SUBSTABELECIMENTO COM RESERVA 07.2022 - C_pia.pdf'\n",
            " 35a5ffee37381d671b1e835ec0f46fe395e54758_PROCURA__O.pdf\n",
            " 3fd316a7ec27b79a000538a6334bce4f5548cbea_Subs..pdf\n",
            "'424a98badac24df3b40e91a8251752b9dcae3371_Doc.3 - Procura__o.pdf'\n",
            "'48a55cda9a2821f15e40ec59f096e04884963b65_Carta de Preposi__o.pdf'\n",
            "'50d150d2d0aa2b5b70f1da9204d7cd9225a562a3_02-Procura__o Fl_vio Patrick.pdf'\n",
            " 603f6211013165ebe2d8937532ecdd1bababf64f_7861512-02dw-3.substabelecimento.pdf\n",
            " 616a051d08b27325464e38da69d0f63b58ff34e7_PROCURA__O.pdf\n",
            "'62a7fbe63f0978daf9a9c693e26a8b14f258837c_4 - Procura__o assinada.pdf'\n",
            " 6913448a34c3621b9bd669a61e947f2ab4651087_8315344-02dw-1.procura__o.pdf\n",
            "'7f332f8fa1c44fd90788ec04be82de649cb29d69_3 Substabelecimento Banco.pdf'\n",
            " 896f7845afa0df0caf6a78aa868e38fd04eb4f6a_PROC.pdf\n",
            "'b120bef89441270e0cd5feb930d7604e2ebb65cb_Procura__o - Hipossufici_ncia  - Honorarios.pdf'\n",
            "'b7eef0f8ac9e51c23f7c321091300ae4a7751834_Procura__o e Substabelcimento_ADR4.pdf'\n",
            " bb91fd5500017b7e46641da8f28abd87189af951_2-CARTA.pdf\n",
            " c9faa2013a5149bb57ae96e2169c7e294a8ba715_procura__o.pdf\n",
            " cdcc958f2bab6e9d226f434c683ceec375b9afe6_Substabelecimento.pdf\n",
            "'d8633ea2df81db2b6f11559aba301c224bf4bbeb_SUBSTABELECIMENTO CIA - ESCRITORIO 2021 - C_pia.pdf'\n",
            "'d99ddf6242faba0fcb4b85b2e05c9792c6dc0787_PROCURA__O BANCO ITAU BMG CONSIGNADO S.A ok ok.pdf'\n",
            "'dba8cc1ee1fbe4cf159477dd6c25e09d1a2db2f1_3 - PROCURA__O.pdf'\n",
            "'ec93ad781ca4d3bbddcd6b322c458d8931e7470a_PROCURA__O de Telma 2022 junho _1_.pdf'\n",
            "'ecbbe8124f902582838c66688d0f6c9e2a86475e_PROCURA__O ASSIN - VICTOR.pdf'\n",
            "\n",
            "'/content/docs_classificados/docs_classificados_2025-07-06/Recurso de apelação (recurso e razões)':\n",
            "6dabcee0d10c1b97545ef2812116bd3bbcab0f07_APELA__O.pdf\n",
            "\n",
            "/content/docs_classificados/docs_classificados_2025-07-06/Réplica:\n",
            "'17627ccd857b700e4bbf163bc191b906e27bf2ab_PETI__O R_PLICA E PROVAS.pdf'\n",
            "'3e61e1e21e37b6ce68598ea2179fd612303dae78_VICTOR MARQUES CARIA  - CDC- 60 dias sem acp-efeito suspensivo-negativa__o.pdf'\n",
            " f9caa66418dc693cd09680fff39f1f8ee2737453.html\n",
            "\n",
            "/content/docs_classificados/docs_classificados_2025-07-06/Sentença:\n",
            "0dd8391afbca730772bfc88b0ab81f07819c03e9.html\n",
            "0dfc75a65288fdd090a732fc0e5c06fdb6425b1e.html\n",
            "8d96f650c71cabe7432599e3ca584dad70792853.html\n",
            "8f0e067f2076b035671de2cad1d409b62e0877bc.html\n",
            "976101ecc0cf818dfc33a175fe5397818b5b093c.html\n",
            "9a530dd8de20e5debc927ceb948c94b3a6c48136.html\n",
            "a6e4afc04416bcd0103f3d2349f7778bfa6a7402.html\n",
            "c827a6d65f0c437bcefa128d63eca65eaf3779de.html\n",
            "d1cd60964f818d263374b16db77c245efc439033.html\n",
            "d212c73989e63a8cf8a0bd503594b5372532081e.html\n",
            "\n",
            "/content/docs_classificados/docs_classificados_2025-07-06/Tréplica:\n",
            "10f0bd3f2f4183f61785bb8d0a79386b773ba026_0800981-51.2023.8.19.0077.pdf\n",
            "\n",
            "Iniciando leitura de arquivos a partir de: /content/docs_classificados/docs_classificados_2025-07-06\n",
            "Processando pasta: Réplica\n",
            "  Encontrados 2 arquivos suportados.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Réplica: 100%|██████████| 2/2 [01:23<00:00, 41.71s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processando pasta: Outros pedidos\n",
            "  Encontrados 5 arquivos suportados.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Outros pedidos: 100%|██████████| 5/5 [00:42<00:00,  8.57s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processando pasta: PI\n",
            "  Encontrados 23 arquivos suportados.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PI: 100%|██████████| 23/23 [25:31<00:00, 66.60s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processando pasta: Contestação\n",
            "  Encontrados 7 arquivos suportados.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rContestação:   0%|          | 0/7 [00:00<?, ?it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Timeout do Tesseract, tempo de processamento e qualidade do output\n",
        "\n",
        "Esse tópico é extremamente importante para o adequado funcionamento do Notebook. Durante o desenvolvimento da sprint, testei vários limites de Timeout, porque isso influenciava diretamente no tempo que demora para rodar tudo e na qualidade do output ao final. Comecei testando timeout de 5s e o modelo todo carregou em menos de 1h, mas deu um número absurdo de falhas e problemas. Testei também com timeouts de 10s, 15s, 30s e 60s. Na minha máquina, o tempo máximo de rodar o modelo foi de pouco mais de 2h, extraindo praticamente todos os documentos da pasta com o timeout de 60s. Contudo, na versão de 30s não perdi tanto e ganhei tempo, o que me levou a deixar aqui o default de 40s. Para fins de avaliação do trabalho, é minha obrigação sinalizar que é possível obter resposta rápida, mas isso vai prejudicar o resultado. Para obter o mesmo resultado positivo que eu obtive, é necessário deixar o timeout de 30s ou mais por documento, o que leva o extrator a tomar cerca de 2h para extrair tudo e rodar os modelos.\n"
      ],
      "metadata": {
        "id": "4teXBjmVlngh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Pré-processamento e vetorização\n",
        "\n",
        "Aplicamos normalização textual para facilitar o aprendizado dos algoritmos.\n",
        "Aqui usei:\n",
        "- Lowercase\n",
        "- Remoção de pontuação\n",
        "- Vetorização TF-IDF (mais robusta para textos jurídicos)\n"
      ],
      "metadata": {
        "id": "iHkdpTA6tkNz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove pontuação\n",
        "    text = re.sub(r'\\d+', '', text)      # Remove números\n",
        "    text = text.strip()\n",
        "    return text\n",
        "\n",
        "# Verifica se o DataFrame não está vazio antes de continuar com o pré-processamento e treinamento\n",
        "if not df.empty:\n",
        "    df['texto_limpo'] = df['texto'].apply(clean_text)"
      ],
      "metadata": {
        "id": "kbCcpKI2vA3K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Otimização de hiperparâmetros\n",
        "\n",
        "A minha otimização de parâmetros eu não fiz seguindo os modelos fornecidos, porque entendi que, para o meu problema, era mais importante eu sinalizar para\n",
        "o modelo quais são os textos que merecem um peso maior durante a classificação.\n",
        "Por isso, não há aqui uma sessão de hiperparâmetros similar aos modelos disponibilizados, mas sim o uso de Regex e uma combinação no eixo X para viabilizar a mesma otimização dos resultados."
      ],
      "metadata": {
        "id": "y7gK1xqbvoGP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # Montei aqui um dicionário de padrões (sinais) para ajudar os modelos, com\n",
        "    # base no meu conhecimento jurídico\n",
        "\n",
        "    strong_signals = {\n",
        "        \"enderecamento\": [\n",
        "            r\"\\bEXCELENT[ÍI]SSIMO(?:A)?\\s+SENHOR(?:A)?\\s+JUIZ(?:A)?\\b\",\n",
        "            r\"\\bEXMO(?:\\.|º)?\\s+SR(?:\\.|ª)?\\s+DR(?:\\.|ª)?\\s+JUIZ\\b\",\n",
        "        ],\n",
        "        \"tutela\": [\n",
        "            r\"\\b(?:[IVX]+|\\d+\\.)?DA[S]?\\s+TUTELA[S]?\\s+(?:DE\\s+)?(?:URG[ÊE]NCI?A|PROVIS[ÓO]RIA|ANTECIPADA)\\b\",\n",
        "            r\"\\bNECESS[ÁA]RIO\\s+DEFERIMENTO\\s+DA\\s+TUTELA\\b\",\n",
        "            r\"\\b(?:[IVX]+|\\d+\\.)?DO[S]?\\s+(?:PEDID[OÓ]?[S]?\\s+)?(?:DE\\s+)?LIMINAR[ES]?\\b\",\n",
        "            r\"\\bTUTELA\\s+ANTECIPADA\\b\",\n",
        "        ],\n",
        "        \"provas\": [\n",
        "            r\"\\b(?:[IVX]+|\\d+\\.)?(?:PROTESTA\\s+(?:POR|O\\s+POR)|REQUER\\s+(?:O[A]?\\s+PRODU[ÇC][ÃA]O\\s+DE)?)\\s+PROVA[S]?\\b\",\n",
        "            r\"\\bREQUER\\s+PROVA[S]?\\b\",\n",
        "        ],\n",
        "        \"encerramento\": [\n",
        "            r\"\\b(?:[IVX]+|\\d+\\.)?(?:TERMO[S]?\\s+EM\\s+QUE|NESTE[S]?\\s+TERMOS)\\b\",\n",
        "            r\"\\bP\\.?E\\.?D\\.?\\b\",\n",
        "            r\"\\b(?:[LO]CAL(?:IDADE)?|CIDADE)\\s*[,;]?\\s*\\d{1,2}\\s+DE\\s+\\w+\\s+DE\\s+\\d{4}\\b\",\n",
        "        ],\n",
        "        \"citacao\": [\n",
        "            r\"\\b(?:[IVX]+|\\d+\\.)?(?:A\\s+)?CITA[ÇC][AÃ]?[OÃ]?[S]?\\s+(?:DA[S]?\\s+)?(?:REQUERIDA[S]?|REQUERIDO[S]?)\\b\",\n",
        "        ],\n",
        "        \"preliminares\": [\n",
        "            r\"\\b(?:[IVX]+|\\d+\\.)?DO[S]?\\s+PRELIMINAR[ES]?\\b\",\n",
        "        ],\n",
        "        \"justica_gratuita\": [\n",
        "            r\"\\b(?:[IVX]+|\\d+\\.)?DA[S]?\\s+(?:GRATUIDADE[S]?\\s+(?:DE\\s+)?JUSTI[ÇC]A|JUSTI[ÇC]A\\s+GRATUITA)\\b\",\n",
        "            r\"\\bGRATUIDADE\\s+DOS\\s+EMOLUMENTOS\\b\",\n",
        "        ],\n",
        "        \"prioridade\": [\n",
        "            r\"\\b(?:[IVX]+|\\d+\\.)?DA[S]?\\s+PRIORIDADE\\s+NA\\s+TRAMITA[ÇC][ÃA]O\\s+PROCESSUAL\\b\",\n",
        "        ],\n",
        "        \"acao\": [\n",
        "            r\"\\bA[ÇC][ÃA]O\\s+(?:DE|REVISIONAL|MONIT[ÓO]RIA|ORDIN[ÁA]RIA|CAUTELAR|INDENIZAT[ÓO]RIA)\\b\",\n",
        "            r\"\\bEXECU[ÇC][ÃA]O\\s+DE\\s+T[ÍI]TULO\\s+EXTRAJUDICIAL\\b\",\n",
        "            r\"\\bVEM\\s+PROPOR\\b\",\n",
        "        ],\n",
        "    }\n",
        "\n",
        "    # Apliquei regex a um texto com a ideia de retornar contagem de matches para\n",
        "    # cada categoria. Quanto mais matches de categoria, maior a chance de um dado\n",
        "    # documento ser uma Petição Inicial. Esse fator é combinado com a fórmula\n",
        "    # como o modelo identifica os padrões tanto do texto restante quanto da\n",
        "    # orientação dos próprios matches de strong signals.\n",
        "\n",
        "    def extract_regex_features(text, signal_dict):\n",
        "        features = {}\n",
        "        for category, patterns in signal_dict.items():\n",
        "            # Conta o número total de vezes que os padrões de categorias acima\n",
        "            # listadas são encontrados\n",
        "            count = sum(len(re.findall(pattern, text, re.IGNORECASE)) for pattern in patterns)\n",
        "            features[f\"feature_{category}\"] = count\n",
        "        return features\n",
        "\n",
        "    # Abaixo está o código para aplicar a função para cada linha do DataFrame e\n",
        "    # criar as novas features\n",
        "    # Usamos o 'texto' original, não o 'texto_limpo', pois os padrões podem\n",
        "    # depender de pontuação/formatação\n",
        "    regex_features_list = df['texto'].apply(lambda text: extract_regex_features(text, strong_signals)).tolist()\n",
        "    regex_features_df = pd.DataFrame(regex_features_list)\n",
        "\n",
        "    # A partir daqui, 'regex_features_df' é um DataFrame com colunas como\n",
        "    # 'feature_enderecamento', 'feature_tutela', etc.\n",
        "    print(\"\\nNovas features criadas a partir dos sinais (Regex):\")\n",
        "    display(regex_features_df.head())\n"
      ],
      "metadata": {
        "id": "UGzHipw2xAHD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Normalização de dados:\n",
        "Vou combinar o regex com o Vectorizer. Para isso, antes preciso excluir o ruído.\n",
        "    "
      ],
      "metadata": {
        "id": "l3KJUzlm0Xwj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definindo uma lista de stop words genéricas do português para evitar ruído\n",
        "# no texto extraído dos documentos\n",
        "\n",
        "    stopwords_pt = ['de', 'a', 'o', 'que', 'e', 'do', 'da', 'em', 'um', 'para',\n",
        "        'com', 'não', 'uma', 'os', 'no', 'se', 'na', 'por', 'mais', 'as', 'dos',\n",
        "        'como', 'mas', 'ao', 'ele', 'das', 'à', 'seu', 'sua']"
      ],
      "metadata": {
        "id": "JFIahK9n0fWt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ajustando o pré-processamento"
      ],
      "metadata": {
        "id": "0FXPCKGy02j0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Usando a lista definida no TfidfVectorizer\n",
        "    vectorizer = TfidfVectorizer(stop_words=stopwords_pt, max_features=3000)\n",
        "    X_tfidf = vectorizer.fit_transform(df['texto_limpo'])\n",
        "    y = (df['classe'] == 'PI').astype(int) # 'PI' = Petição Inicial\n",
        "    # 1 para Petição Inicial, 0 para demais\n",
        "\n",
        "    # Convertendo o DataFrame de features de regex para o formato de matriz esparsa\n",
        "    X_regex = csr_matrix(regex_features_df.values)\n",
        "\n",
        "    # Combinando as duas matrizes de features horizontalmente para ter um único X\n",
        "    X_combined = hstack([X_tfidf, X_regex])\n",
        "\n",
        "    print(f\"\\nFormato da matriz TF-IDF: {X_tfidf.shape}\")\n",
        "    print(f\"Formato da matriz de Regex: {X_regex.shape}\")\n",
        "    print(f\"Formato da matriz Combinada: {X_combined.shape}\")\n"
      ],
      "metadata": {
        "id": "deapnnak1K43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Divisão treino/teste\n",
        "Usaremos 80% dos processos para treino e 20% para teste, garantindo que nenhum documento de mesmo processo caia em ambos os conjuntos.\n"
      ],
      "metadata": {
        "id": "PSWjgzT_1qV3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    test_size = 0.20 # tamanho do conjunto de teste\n",
        "    seed = 7 # semente aleatória\n",
        "\n",
        "    if len(np.unique(y)) < 2:\n",
        "        print(\"\\nErro: O dataset contém apenas uma classe após a extração e pré-processamento. Não é possível dividir em treino/teste com estratificação.\")\n",
        "    else:\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X_combined, y,\n",
        "            test_size=test_size, shuffle=True, random_state=seed, stratify=y) # holdout com estratificação\n",
        "\n",
        "## Parâmetros e partições da validação cruzada\n",
        "    scoring = 'accuracy'\n",
        "    num_particoes = 10\n",
        "    kfold = StratifiedKFold(n_splits=num_particoes, shuffle=True, random_state=seed) # crossvalidation com estratificação\n"
      ],
      "metadata": {
        "id": "F51DA-Ah1zRm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Treinamento dos algoritmos clássicos\n",
        "\n",
        "Aqui testaremos quatro algoritmos: Naive Bayes, SVM, Árvore de Decisão e KNN,\n",
        "observando suas particularidades para classificação de texto."
      ],
      "metadata": {
        "id": "xBzEs-KB19qK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(7) # definindo uma semente global\n",
        "\n",
        "    # Lista que armazenará os modelos\n",
        "    models = []\n",
        "\n",
        "    # Criando os modelos e adicionando-os na lista de modelos\n",
        "        models.append(('KNN', KNeighborsClassifier()))\n",
        "        models.append(('CART', DecisionTreeClassifier()))\n",
        "        # GaussianNB requires dense data, convert X_train if needed within the loop\n",
        "        models.append(('NB', GaussianNB()))\n",
        "        # LinearSVC is generally better for text classification than SVC\n",
        "        models.append(('SVM', LinearSVC(random_state=seed)))\n",
        "\n",
        "        # Listas para armazenar os resultados\n",
        "        results = []\n",
        "        names = []\n",
        "        scoring_results = [] # To store results for analysis and export"
      ],
      "metadata": {
        "id": "XGjkGWR226s9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Avaliação e comparação dos modelos"
      ],
      "metadata": {
        "id": "mHXfgvjt3H8T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nAvaliando modelos...\")\n",
        "        for name, model in models:\n",
        "            try:\n",
        "                if isinstance(model, GaussianNB):\n",
        "                     # Converte para array denso se for GaussianNB\n",
        "                     cv_results = cross_val_score(model, X_train.toarray(), y_train, cv=kfold, scoring=scoring)\n",
        "                else:\n",
        "                    cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n",
        "\n",
        "                results.append(cv_results)\n",
        "                names.append(name)\n",
        "                msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
        "                print(msg)\n",
        "                scoring_results.append({'Algoritmo': name, 'Mean Accuracy': cv_results.mean(), 'Std Dev Accuracy': cv_results.std()})\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Erro ao avaliar o modelo {name}: {e}\")\n",
        "                # Não pare a execução se um modelo falhar, apenas imprima o error\n",
        "                continue\n",
        "\n",
        "    # Boxplot de comparação dos modelos\n",
        "        if results: # Só tenta plotar se houver resultados\n",
        "            fig = plt.figure(figsize=(15,10))\n",
        "            fig.suptitle('Comparação dos Modelos')\n",
        "            ax = fig.add_subplot(111)\n",
        "            plt.boxplot(results)\n",
        "            ax.set_xticklabels(names)\n",
        "            plt.show()\n",
        "        else:\n",
        "            print(\"\\nNenhum resultado de modelo para plotar.\")\n",
        "\n",
        "        print(\"\\nAnálise dos resultados: (Este é um placeholder. Analise os resultados acima para descrever o desempenho de cada modelo aqui.)\")\n",
        "\n",
        "## Avaliação do melhor modelo com base nos testes\n",
        "        print(\"\\nAvaliação do modelo com o conjunto de testes\")\n",
        "\n",
        "## Determinando o melhor modelo com base nos resultados de cross-validation\n",
        "        if scoring_results:\n",
        "            results_df = pd.DataFrame(scoring_results)\n",
        "            # Lidando com dataframe vazio em caso de falhas\n",
        "            if not results_df.empty:\n",
        "                best_model_name = results_df.loc[results_df['Mean Accuracy'].idxmax(), 'Algoritmo']\n",
        "                print(f\"\\nMelhor modelo baseado na acurácia média da validação cruzada: {best_model_name}\")\n",
        "\n",
        "## Retreinando o melhor modelo com toda a base de dados de treino para garantir\n",
        "## o melhor resultado ao exportar os arquivos .pkl\n",
        "\n",
        "                best_model = None\n",
        "                if best_model_name == 'KNN':\n",
        "                    best_model = KNeighborsClassifier()\n",
        "                elif best_model_name == 'CART':\n",
        "                    best_model = DecisionTreeClassifier(random_state=seed)\n",
        "                elif best_model_name == 'NB':\n",
        "                     best_model = GaussianNB()\n",
        "                elif best_model_name == 'SVM':\n",
        "                    best_model = LinearSVC(random_state=seed) # Use LinearSVC for text\n",
        "\n",
        "                if best_model:\n",
        "                    try:\n",
        "                        if isinstance(best_model, GaussianNB):\n",
        "                             best_model.fit(X_train.toarray(), y_train)\n",
        "                             predictions = best_model.predict(X_test.toarray())\n",
        "                        else:\n",
        "                            best_model.fit(X_train, y_train)\n",
        "                            predictions = best_model.predict(X_test)\n",
        "\n",
        "                        print(\"\\nAvaliação no conjunto de teste:\")\n",
        "                        print(\"Accuracy:\", accuracy_score(y_test, predictions))\n",
        "                        print(\"F1-score:\", f1_score(y_test, predictions))\n",
        "                        print(\"\\nClassification Report:\\n\", classification_report(y_test, predictions))\n",
        "                        print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, predictions))"
      ],
      "metadata": {
        "id": "NdCdEIdp3WGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exportação do modelo vencedor"
      ],
      "metadata": {
        "id": "intDrfN-39en"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Salvamos o melhor modelo como arquivo .pkl, pronto para integração com a aplicação web.\n",
        "\n",
        "                        print(f\"\\nExportando o modelo vencedor: {best_model_name}\")\n",
        "                        joblib.dump(best_model, 'modelo_peticao_inicial.pkl')\n",
        "                        joblib.dump(vectorizer, 'vectorizer_peticao.pkl')\n",
        "                        print(\"Modelo e Vectorizer exportados com sucesso.\")"
      ],
      "metadata": {
        "id": "4omSIN7L4AQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Teste automatizado do modelo\n",
        "\n",
        "Implementei aqui o teste automatizado para assegurar que o modelo atenda aos requisitos de desempenho estabelecidos. Não fiz no backend porque ele é muito simples e a falta de persistência dos dados faz com que não seja possível testar naquele ambiente. No backend eu fiz um teste de validação da precisão distinto, que pode ser conferido no documento test_api.py lá. Aqui cumpri o requisito de ter um teste automatizado para assegurar que o modelo atenda aos requisitos de desempenho estabelecidos. A métrica se baseou no problema real, em que o usuário chega a errar 30% ou mais da classificação dos documentos no sistema PJe. Assim, o teste foi criado para garantir que o modelo só seja aceito se atingir um F1-score mínimo pré-definido de 75%, que justificaria seu uso em correção ao que faz o usuário atualmente de forma manual."
      ],
      "metadata": {
        "id": "CF185yrv4H7I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "                        print(\"\\nExecutando teste automatizado do modelo vencedor...\")\n",
        "                        def test_model_performance(model, X_test, y_test, threshold=0.75):\n",
        "                            from sklearn.metrics import f1_score\n",
        "                            # Regra especial para o tratamento do GaussianNB\n",
        "                            if isinstance(model, GaussianNB):\n",
        "                                y_pred = model.predict(X_test.toarray())\n",
        "                            else:\n",
        "                                y_pred = model.predict(X_test)\n",
        "                            f1 = f1_score(y_test, y_pred)\n",
        "                            assert f1 >= threshold, f\"F1-score abaixo do esperado: {f1:.2f} (esperado >= {threshold:.2f})\"\n",
        "                            print(f\"Teste automatizado passou: F1-score = {f1:.2f}\")\n",
        "\n",
        "                        try:\n",
        "                            # Use o modelo vencedor e os dados de teste\n",
        "                            test_model_performance(best_model, X_test, y_test, threshold=0.75)\n",
        "                        except AssertionError as e:\n",
        "                            print(f\"Teste automatizado falhou: {e}\")\n",
        "                        except Exception as e:\n",
        "                            print(f\"Ocorreu um erro durante o teste automatizado: {e}\")\n",
        "\n",
        "                    except Exception as e:\n",
        "                        print(f\"Erro ao treinar ou avaliar o melhor modelo ({best_model_name}) no conjunto de teste: {e}\")\n",
        "                        traceback.print_exc()\n",
        "                else:\n",
        "                     print(\"\\nNão foi possível encontrar o objeto do melhor modelo para exportação.\")\n",
        "\n",
        "            else:\n",
        "                 print(\"\\nNão há resultados de modelos para determinar o melhor modelo.\")\n",
        "        else:\n",
        "            print(\"\\nNenhum modelo foi avaliado com sucesso.\")\n",
        "\n",
        "else:\n",
        "    print(\"\\nDataFrame está vazio. Não é possível prosseguir com pré-processamento, treino e avaliação.\")\n"
      ],
      "metadata": {
        "id": "kOPVdwoY6AJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Análise dos resultados\n",
        "\n",
        "Os resultados mostram que o algoritmo de Árvore de Decisão obteve o melhor desempenho, oscilando entre 95% a 100% de acertos nos testes. No pior cenário, ele acertou 80% das petições iniciais que identificou, apontando 1 falso positivo.\n",
        "O resultado foi bastante destacado, mesmo em se considerando que todos os modelos foram muito bem. O resultado de alto acerto tem certamente relação com a combinação com Regex e os sinais fortes, mas não pode ser atribuído só a isso, considerando-se o próprio destaque do modelo de árvore de decisão sobre os demais.\n",
        "O motivo principal do sucesso tem relação com o problema, uma vez que os modelos de árvore de decisão são conhecidos por funcionarem bem em contextos jurídicos, em especial classificações como essa e o uso de Árvores de Classificação, quando o modelo tem que decidir se algo tem a caractertística de determinada classe ou não e seguir para a próxima bifurcação de decisão.\n",
        "A combinação de precião na decisão de um atributo com os sinais positivos de Regex ainda potencializou mais este modelo que os demais."
      ],
      "metadata": {
        "id": "LteuwHNr6Egl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusão\n",
        "\n",
        "Neste notebook, mostrei todo o pipeline de identificação automática de Petições Iniciais, comentando o problema e a forma de sua solução que encontrei aqui. Ao longo do notebook, foi possível encontrar tudo que foi pedido no exercício, incluindo pré-processamento, normalização dos dados, otimização de parâmetros, avaliação de algoritmos clássicos, escolha do modelo vencedor e preparação para integração full stack. A isso, some-se o esforço de também entregar o backend e o front-end para integrar a aplicação full stack.\n",
        "Por fim, quanto ao problema em si, o resultado geral e próximos passos, entendo que parte dos motivos de um resultado tão positivo tem a ver com o tamanho enxuto da base de dados. Gostaria de, no futuro, submetê-lo a uma base maior (que eu até tenho aqui classificada, mas sem o mesmo rigor dessa base ouro usada aqui).\n",
        "Entendo que, em especial o pkl combinado aqui deste notebook pode ser realmente útil em trabalhos reais no futuro. Antes disso, todavia, quero estressar mais os 4 modelos, em especial o CART, para ver se esse resultado excelente se repete em vários cenários. Em caso positivo, é possível que uma grande quantidade de processos judiciais reais tenham os dados que os identificam finalmente corrigidos nos bancos de dados do Judiciário, viabilizando uma série de melhorias de longo prazo para aqueles que mais precisam da Justiça."
      ],
      "metadata": {
        "id": "uo-ke2d064ef"
      }
    }
  ]
}