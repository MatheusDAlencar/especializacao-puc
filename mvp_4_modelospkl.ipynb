{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM7nKEgyZiJAqZtKdAs91ap",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MatheusDAlencar/especializacao-puc/blob/main/mvp_4_modelospkl.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MVP Identificador de Petição Inicial\n",
        "\n",
        "Este notebook documenta e executa todo o ciclo de criação de um modelo clássico de machine learning para classificar documentos jurídicos como “Petição Inicial\" ou não, usando um dataset real. O processo é transparente, modular e compatível com integração full stack. Todos os passos estarão explicados e justificados a seguir, facilitando a execução autônoma e a avaliação do trabalho.\n",
        "\n",
        "\n",
        "## Resolução do \"problema Petição Inicial\": por quê?\n",
        "\n",
        "O projeto se baseia em um projeto real que toquei ao longo de 2025. Trata-se de um classificador de documentos. Ele se faz necessário porque, em geral, os sistemas de processo judicial eletrônico sofrem muito com inputs de dados imprecisos dos usuários e um classificador de petições iniciais seria um primeiro passo muito importante visando o objetivo final de correção do problema apontado. Esse problema é particularmente importante porque ele é a causa da extrema dificuldade atual de planejar qualquer estruturação do Sistema de Justiça com base em dados, visando aumentar sua eficiência. Em síntese, as informações disponíveis não são confiáveis, uma vez que são extraídas dos sistemas de processo judicial eletrônico, mas eles são alimentados por usuários do mundo jurídico, que, na média, têm muito baixo cuidado com a precisão e qualidade dos dados que são inseridos nos sistemas.\n",
        "\n",
        "Isso leva a problemas como, por exemplo, não se saber exatamente quantos processos de cada matéria existem de fato, uma vez que isso dependeria de uma adequada classificação de classe e assunto de todos os processos conforme as tabelas processuais unificadas do CNJ (conferir em: <https://www.cnj.jus.br/sgt/consulta_publica_assuntos.php> e <https://www.cnj.jus.br/sgt/consulta_publica_classes.php>). Como isso não ocorre, fica-se sem saber a realidade do que se discute de fato no Judiciário.\n",
        "\n",
        "Para corrigir esse problema, seria necessário automatizar a reclassificação de classes e assuntos dos processos. Isso, contudo, traz outro problema anterior: quais documentos servem para reclassificar classe e assunto de um processo em andamento? Aí entra o papel do classificador de documentos. Em geral, o documento que delimita a classe e o assunto de um processo é a petição inicial, daí a importância de saber se um documento é ou não petição inicial, para, por meio dele, no futuro, encontrar a classe e o assunto de um processo judicial, permitindo a correção das bases de dados e diagnósticos mais precisos da realidade do Judiciário, viabilizando modelos de gestão baseados em evidências e, em última instância, a eficiência administrativa na prestação do serviço de Justiça aos cidadãos que mais necessitam da pronta e justa resposta judicial."
      ],
      "metadata": {
        "id": "VG5i_UFletlk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "## Iniciando o código ##\n",
        "## Imports necessários\n",
        "\n",
        "# Instalando bibliotecas que não estão aqui by default\n",
        "!pip install pytesseract pdf2image\n",
        "!sudo apt-get update\n",
        "!sudo apt-get install -y tesseract-ocr libtesseract-dev tesseract-ocr-por\n",
        "!sudo apt-get install -y poppler-utils\n",
        "\n",
        "# Outros imports\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import zipfile\n",
        "import joblib\n",
        "import os\n",
        "import pytesseract\n",
        "import glob\n",
        "import tqdm\n",
        "import re\n",
        "import numpy as np\n",
        "import traceback\n",
        "from pdf2image import convert_from_path\n",
        "from sklearn.model_selection import train_test_split,\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from google.colab import drive\n",
        "from scipy.sparse import hstack, csr_matrix\n",
        "\n",
        "# Comentários sobre os imports\n",
        "# Foram escolhidas ferramentas de classificação e predição mais aderentes ao\n",
        "# problema enfrentado, em especial oscerizar PDFs para permitir a classificação.\n",
        "\n",
        "## Montando o Google Drive\n",
        "# Nesta etapa, montamos o Google Drive para acessar o dataset de documentos\n",
        "# classificados que vão formar nossa base de dados de treino e de testes.\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Eu autorizei o acesso do Colab ao meu Google Drive e isso pode ser pedido a\n",
        "# quem inspecionar este código também. Todavia, não precisa haver preocupação\n",
        "# quanto à origem da pasta dos dados, pois a pasta do meu Drive é pública e tem\n",
        "# até uma pasta extra com mais dados, que eu diminuí para deixar o modelo aqui\n",
        "# mais performático."
      ],
      "metadata": {
        "id": "SB37eKDRgD3v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sobre o Dataset\n",
        "\n",
        "Como o Colab permite acessar um link do Drive público, montei uma pasta com documentos jurídicos classificados por mim. O dataset foi disponibilizado em (https://drive.google.com/drive/folders/1bhDT4BUMF2CjViTMBJpmNmMZ3dy6RXtU?usp=drive_link) e contém subpastas nomeadas com o tipo da peça jurídica. Cada pasta representa uma classe, facilitando o uso de aprendizado supervisionado clássico. O objetivo central é identificar, entre todos os documentos, quais são “Petição Inicial”, identificados dentro das pastas de nome \"PI\" dentro das pastas de processos.\n",
        "\n",
        "Exemplo de estrutura de diretórios:\n",
        "\n",
        "- Petição Inicial/\n",
        "- Contestação/\n",
        "- Réplica/\n",
        "- Outros/\n",
        "\n",
        "Cada pasta contém documentos PDF já classificados, mas montei o classificador de tal forma que permita também classificar arquivos JPG ou PNG, além do PDF, para que ele se torne, é claro, mais útil e de fácil uso.\n"
      ],
      "metadata": {
        "id": "CE4Lucn-g3LV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Leitura dos arquivos e preparação da base\n",
        "\n",
        "Aqui lemos todos os documentos do diretório extraído, associando o nome da pasta como rótulo (classe). Arquivos de texto são lidos diretamente, PDFs via pdf2image + OCR, imagens via OCR.\n",
        "\n",
        "A leitura se dá por meio do Loop de leitura das pastas e seus documentos. É muito importante que ocorra seu correto funcionamento, ou ficaremos sem os dados, impedindo o adequado funcionamento de basicamente tudo."
      ],
      "metadata": {
        "id": "AhB3vkOTrBsE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Para facilitar a estruturação dos dados, trouxe a pasta como .zip, então será\n",
        "# necessário extrair o zip\n",
        "\n",
        "zip_path = '/content/drive/MyDrive/Dataset_juridico/docs_classificados_2025-07-06.zip'\n",
        "extract_dir = '/content/docs_classificados'\n",
        "\n",
        "# Removendo o diretório de extração anterior para garantir uma extração limpa\n",
        "if os.path.exists(extract_dir):\n",
        "    import shutil\n",
        "    shutil.rmtree(extract_dir)\n",
        "os.makedirs(extract_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "# Coloquei vários trechos de código para me servirem como log, para saber o que\n",
        "# poderia dar problema e onde, porque o modelo é por si pesado e a extração dos\n",
        "# documentos demora muito, então eu não podia ficar travando a todo momento ou\n",
        "# tomando erro sem resposta.\n",
        "\n",
        "try:\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_dir)\n",
        "    print(f\"Arquivo ZIP extraído com sucesso para: {extract_dir}\")\n",
        "    # Verificar o conteúdo após a extração\n",
        "    print(\"\\nConteúdo do diretório extraído:\")\n",
        "    !ls -R {extract_dir}\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"Erro: Arquivo ZIP NÃO encontrado no caminho: {zip_path}\")\n",
        "    print(\"POR FAVOR, VERIFIQUE E CORRIJA O CAMINHO DO ARQUIVO ZIP NO SEU GOOGLE DRIVE NA LINHA 'zip_path = ...'\")\n",
        "    # Interromper a execução se o arquivo ZIP não for encontrado\n",
        "    raise\n",
        "except Exception as e:\n",
        "    print(f\"Ocorreu um erro durante a extração do ZIP: {e}\")\n",
        "    # Interromper a execução em caso de outros erros de extração\n",
        "    raise\n",
        "\n",
        "def extract_text_from_pdf(file_path):\n",
        "    try:\n",
        "        pages = convert_from_path(file_path, timeout=40)\n",
        "        text = \"\"\n",
        "        for page in pages:\n",
        "            text += pytesseract.image_to_string(page, lang='por', timeout=40)\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        print(f\"Erro na extração de texto do PDF {file_path}: {e}\")\n",
        "        # Imprimir o traceback completo para depuração\n",
        "        traceback.print_exc()\n",
        "        # Retornar uma string vazia em caso de erro\n",
        "        return \"\"\n",
        "\n",
        "def extract_text_from_image(file_path):\n",
        "    try:\n",
        "        from PIL import Image\n",
        "        img = Image.open(file_path)\n",
        "        text = pytesseract.image_to_string(img, lang='por', timeout=40)\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        print(f\"Erro na extração de texto da imagem {file_path}: {e}\")\n",
        "        # Imprimir o traceback completo para depuração\n",
        "        traceback.print_exc()\n",
        "        # Retornar uma string vazia em caso de erro\n",
        "        return \"\"\n",
        "\n",
        "data = []\n",
        "# Define o caminho para a pasta que contém as subpastas de classes. Sem isso, o\n",
        "# extrator não chega até os documentos necessários\n",
        "base_dir_for_classes = os.path.join(extract_dir, 'docs_classificados_2025-07-06')\n",
        "\n",
        "print(f\"\\nIniciando leitura de arquivos a partir de: {base_dir_for_classes}\")\n",
        "\n",
        "# Verifica se o diretório-base para as classes de documentos existe\n",
        "if not os.path.exists(base_dir_for_classes):\n",
        "    print(f\"Erro: O diretório base para as classes '{base_dir_for_classes}' não foi encontrado após a extração.\")\n",
        "    print(\"Por favor, verifique a estrutura do seu ZIP e o nome da pasta que contém as classes dentro dele.\")\n",
        "else:\n",
        "    # Itera sobre as pastas de classe de documentos dentro do diretório base\n",
        "    for class_dir_name in os.listdir(base_dir_for_classes):\n",
        "        class_path = os.path.join(base_dir_for_classes, class_dir_name)\n",
        "        # Verifica se o item é um diretório (que deve ser uma pasta de classe de documento)\n",
        "        if os.path.isdir(class_path):\n",
        "            print(f\"Processando pasta: {class_dir_name}\")\n",
        "            # Usando glob para encontrar arquivos com as extensões esperadas\n",
        "            file_patterns = ['*.pdf', '*.jpg', '*.jpeg', '*.png']\n",
        "            files_in_class_dir = []\n",
        "            for pattern in file_patterns:\n",
        "                files_in_class_dir.extend(glob.glob(os.path.join(class_path, pattern)))\n",
        "\n",
        "            if not files_in_class_dir:\n",
        "                 print(f\"  Aviso: Nenhum arquivo suportado encontrado na pasta {class_dir_name}. Pulando.\")\n",
        "                 continue # Pula para a próxima pasta se não encontrar arquivos\n",
        "\n",
        "            # Adiciona uma impressão para mostrar quantos arquivos foram encontrados na pasta\n",
        "            print(f\"  Encontrados {len(files_in_class_dir)} arquivos suportados.\")\n",
        "\n",
        "            for fpath in tqdm.tqdm(files_in_class_dir, desc=class_dir_name):\n",
        "                fname = os.path.basename(fpath) # Obtém o nome do caminho completo do arquivo\n",
        "\n",
        "                text = \"\" # Inicializa como texto vazio para cada arquivo\n",
        "                # print(f\"  Tentando extrair texto de: {fpath}\") #desabilitado para\n",
        "                # fins de performance, mas deixei aqui para o uso caso eu\n",
        "                # percebesse que essa parte estava dando erro\n",
        "\n",
        "                if fpath.lower().endswith('.pdf'):\n",
        "                    text = extract_text_from_pdf(fpath)\n",
        "                elif fpath.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    text = extract_text_from_image(fpath)\n",
        "\n",
        "                # Só adiciona se houver texto extraído (pelo menos 1 caracter após strip)\n",
        "                if text and text.strip():\n",
        "                     # print(f\"  Texto extraído (primeiros 50 chars): {text.strip()[:50]}...\")\n",
        "                     # Print de depuração, desabilitado para fins de performance\n",
        "                     # Desabilitação e manutenção no código por motivos idênticos\n",
        "                     # aos do comentário do bloco acima.\n",
        "                     data.append({'texto': text, 'classe': class_dir_name, 'arquivo': fname})\n",
        "                else:\n",
        "                    # A mensagem de erro detalhada já será impressa pelas funções de extração,\n",
        "                    # mas este print confirma que o arquivo foi processado e não retornou texto.\n",
        "                    # print(f\"  Aviso: Nenhum texto extraído ou texto vazio do arquivo {fpath}. Pulando.\")\n",
        "                    # Desabilitação e manutenção no código por motivos idênticos\n",
        "                    # aos dos comentários dos blocos acima.\n",
        "                    pass\n",
        "\n",
        "print(f\"\\nLeitura de arquivos concluída. Tamanho da lista de dados: {len(data)}\")\n",
        "print(\"Primeiros 5 itens na lista de dados:\")\n",
        "# Imprime os primeiros 5 itens, verificando se a lista não está vazia\n",
        "\n",
        "if data:\n",
        "    # Limita a impressão para não sobrecarregar a saída se os textos forem muito longos\n",
        "    for item in data[:5]:\n",
        "        print({k: (v if k != 'texto' else v[:100] + '...' if len(v) > 100 else v) for k, v in item.items()})\n",
        "else:\n",
        "    print(\"A lista de dados está vazia.\")\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "# Para garantir que o DataFrame só seja criado se data não estiver vazia,\n",
        "# ou avisar se for o caso de DataFrame vazio.\n",
        "if not df.empty:\n",
        "    # Não precisamos mais remover vazios aqui se já filtramos ao adicionar na lista 'data')\n",
        "    # df = df[df['texto'].str.strip().astype(bool)]\n",
        "    print(\"\\nDataFrame criado.\")\n",
        "    display(df.head())\n",
        "else:\n",
        "    print(\"\\nDataFrame vazio criado, pois a lista de dados estava vazia ou a extração de texto falhou para todos os arquivos.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "1qYxPeVgqc3O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Timeout do Tesseract, tempo de processamento e qualidade do output\n",
        "\n",
        "Esse tópico é extremamente importante para o adequado funcionamento do Notebook. Durante o desenvolvimento da sprint, testei vários limites de Timeout, porque isso influenciava diretamente no tempo que demora para rodar tudo e na qualidade do output ao final. Comecei testando timeout de 5s e o modelo todo carregou em menos de 1h, mas deu um número absurdo de falhas e problemas. Testei também com timeouts de 10s, 15s, 30s e 60s. Na minha máquina, o tempo máximo de rodar o modelo foi de pouco mais de 2h, extraindo praticamente todos os documentos da pasta com o timeout de 60s. Contudo, na versão de 30s não perdi tanto e ganhei tempo, o que me levou a deixar aqui o default de 40s. Para fins de avaliação do trabalho, é minha obrigação sinalizar que é possível obter resposta rápida, mas isso vai prejudicar o resultado. Para obter o mesmo resultado positivo que eu obtive, é necessário deixar o timeout de 30s ou mais por documento, o que leva o extrator a tomar cerca de 2h para extrair tudo e rodar os modelos.\n"
      ],
      "metadata": {
        "id": "4teXBjmVlngh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Pré-processamento e vetorização\n",
        "\n",
        "Aplicamos normalização textual para facilitar o aprendizado dos algoritmos.\n",
        "Aqui usei:\n",
        "- Lowercase\n",
        "- Remoção de pontuação\n",
        "- Vetorização TF-IDF (mais robusta para textos jurídicos)\n"
      ],
      "metadata": {
        "id": "iHkdpTA6tkNz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove pontuação\n",
        "    text = re.sub(r'\\d+', '', text)      # Remove números\n",
        "    text = text.strip()\n",
        "    return text\n",
        "\n",
        "# Verifica se o DataFrame não está vazio antes de continuar com o pré-processamento e treinamento\n",
        "if not df.empty:\n",
        "    df['texto_limpo'] = df['texto'].apply(clean_text)"
      ],
      "metadata": {
        "id": "kbCcpKI2vA3K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Otimização de hiperparâmetros\n",
        "\n",
        "A minha otimização de parâmetros eu não fiz seguindo os modelos fornecidos, porque entendi que, para o meu problema, era mais importante eu sinalizar para\n",
        "o modelo quais são os textos que merecem um peso maior durante a classificação.\n",
        "Por isso, não há aqui uma sessão de hiperparâmetros similar aos modelos disponibilizados, mas sim o uso de Regex e uma combinação no eixo X para viabilizar a mesma otimização dos resultados."
      ],
      "metadata": {
        "id": "y7gK1xqbvoGP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # Montei aqui um dicionário de padrões (sinais) para ajudar os modelos, com\n",
        "    # base no meu conhecimento jurídico\n",
        "\n",
        "    strong_signals = {\n",
        "        \"enderecamento\": [\n",
        "            r\"\\bEXCELENT[ÍI]SSIMO(?:A)?\\s+SENHOR(?:A)?\\s+JUIZ(?:A)?\\b\",\n",
        "            r\"\\bEXMO(?:\\.|º)?\\s+SR(?:\\.|ª)?\\s+DR(?:\\.|ª)?\\s+JUIZ\\b\",\n",
        "        ],\n",
        "        \"tutela\": [\n",
        "            r\"\\b(?:[IVX]+|\\d+\\.)?DA[S]?\\s+TUTELA[S]?\\s+(?:DE\\s+)?(?:URG[ÊE]NCI?A|PROVIS[ÓO]RIA|ANTECIPADA)\\b\",\n",
        "            r\"\\bNECESS[ÁA]RIO\\s+DEFERIMENTO\\s+DA\\s+TUTELA\\b\",\n",
        "            r\"\\b(?:[IVX]+|\\d+\\.)?DO[S]?\\s+(?:PEDID[OÓ]?[S]?\\s+)?(?:DE\\s+)?LIMINAR[ES]?\\b\",\n",
        "            r\"\\bTUTELA\\s+ANTECIPADA\\b\",\n",
        "        ],\n",
        "        \"provas\": [\n",
        "            r\"\\b(?:[IVX]+|\\d+\\.)?(?:PROTESTA\\s+(?:POR|O\\s+POR)|REQUER\\s+(?:O[A]?\\s+PRODU[ÇC][ÃA]O\\s+DE)?)\\s+PROVA[S]?\\b\",\n",
        "            r\"\\bREQUER\\s+PROVA[S]?\\b\",\n",
        "        ],\n",
        "        \"encerramento\": [\n",
        "            r\"\\b(?:[IVX]+|\\d+\\.)?(?:TERMO[S]?\\s+EM\\s+QUE|NESTE[S]?\\s+TERMOS)\\b\",\n",
        "            r\"\\bP\\.?E\\.?D\\.?\\b\",\n",
        "            r\"\\b(?:[LO]CAL(?:IDADE)?|CIDADE)\\s*[,;]?\\s*\\d{1,2}\\s+DE\\s+\\w+\\s+DE\\s+\\d{4}\\b\",\n",
        "        ],\n",
        "        \"citacao\": [\n",
        "            r\"\\b(?:[IVX]+|\\d+\\.)?(?:A\\s+)?CITA[ÇC][AÃ]?[OÃ]?[S]?\\s+(?:DA[S]?\\s+)?(?:REQUERIDA[S]?|REQUERIDO[S]?)\\b\",\n",
        "        ],\n",
        "        \"preliminares\": [\n",
        "            r\"\\b(?:[IVX]+|\\d+\\.)?DO[S]?\\s+PRELIMINAR[ES]?\\b\",\n",
        "        ],\n",
        "        \"justica_gratuita\": [\n",
        "            r\"\\b(?:[IVX]+|\\d+\\.)?DA[S]?\\s+(?:GRATUIDADE[S]?\\s+(?:DE\\s+)?JUSTI[ÇC]A|JUSTI[ÇC]A\\s+GRATUITA)\\b\",\n",
        "            r\"\\bGRATUIDADE\\s+DOS\\s+EMOLUMENTOS\\b\",\n",
        "        ],\n",
        "        \"prioridade\": [\n",
        "            r\"\\b(?:[IVX]+|\\d+\\.)?DA[S]?\\s+PRIORIDADE\\s+NA\\s+TRAMITA[ÇC][ÃA]O\\s+PROCESSUAL\\b\",\n",
        "        ],\n",
        "        \"acao\": [\n",
        "            r\"\\bA[ÇC][ÃA]O\\s+(?:DE|REVISIONAL|MONIT[ÓO]RIA|ORDIN[ÁA]RIA|CAUTELAR|INDENIZAT[ÓO]RIA)\\b\",\n",
        "            r\"\\bEXECU[ÇC][ÃA]O\\s+DE\\s+T[ÍI]TULO\\s+EXTRAJUDICIAL\\b\",\n",
        "            r\"\\bVEM\\s+PROPOR\\b\",\n",
        "        ],\n",
        "    }\n",
        "\n",
        "    # Apliquei regex a um texto com a ideia de retornar contagem de matches para\n",
        "    # cada categoria. Quanto mais matches de categoria, maior a chance de um dado\n",
        "    # documento ser uma Petição Inicial. Esse fator é combinado com a fórmula\n",
        "    # como o modelo identifica os padrões tanto do texto restante quanto da\n",
        "    # orientação dos próprios matches de strong signals.\n",
        "\n",
        "    def extract_regex_features(text, signal_dict):\n",
        "        features = {}\n",
        "        for category, patterns in signal_dict.items():\n",
        "            # Conta o número total de vezes que os padrões de categorias acima\n",
        "            # listadas são encontrados\n",
        "            count = sum(len(re.findall(pattern, text, re.IGNORECASE)) for pattern in patterns)\n",
        "            features[f\"feature_{category}\"] = count\n",
        "        return features\n",
        "\n",
        "    # Abaixo está o código para aplicar a função para cada linha do DataFrame e\n",
        "    # criar as novas features\n",
        "    # Usamos o 'texto' original, não o 'texto_limpo', pois os padrões podem\n",
        "    # depender de pontuação/formatação\n",
        "    regex_features_list = df['texto'].apply(lambda text: extract_regex_features(text, strong_signals)).tolist()\n",
        "    regex_features_df = pd.DataFrame(regex_features_list)\n",
        "\n",
        "    # A partir daqui, 'regex_features_df' é um DataFrame com colunas como\n",
        "    # 'feature_enderecamento', 'feature_tutela', etc.\n",
        "    print(\"\\nNovas features criadas a partir dos sinais (Regex):\")\n",
        "    display(regex_features_df.head())\n"
      ],
      "metadata": {
        "id": "UGzHipw2xAHD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Normalização de dados:\n",
        "Vou combinar o regex com o Vectorizer. Para isso, antes preciso excluir o ruído.\n",
        "    "
      ],
      "metadata": {
        "id": "l3KJUzlm0Xwj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definindo uma lista de stop words genéricas do português para evitar ruído\n",
        "# no texto extraído dos documentos\n",
        "\n",
        "    stopwords_pt = ['de', 'a', 'o', 'que', 'e', 'do', 'da', 'em', 'um', 'para',\n",
        "        'com', 'não', 'uma', 'os', 'no', 'se', 'na', 'por', 'mais', 'as', 'dos',\n",
        "        'como', 'mas', 'ao', 'ele', 'das', 'à', 'seu', 'sua']"
      ],
      "metadata": {
        "id": "JFIahK9n0fWt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ajustando o pré-processamento"
      ],
      "metadata": {
        "id": "0FXPCKGy02j0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Usando a lista definida no TfidfVectorizer\n",
        "    vectorizer = TfidfVectorizer(stop_words=stopwords_pt, max_features=3000)\n",
        "    X_tfidf = vectorizer.fit_transform(df['texto_limpo'])\n",
        "    y = (df['classe'] == 'PI').astype(int) # 'PI' = Petição Inicial\n",
        "    # 1 para Petição Inicial, 0 para demais\n",
        "\n",
        "    # Convertendo o DataFrame de features de regex para o formato de matriz esparsa\n",
        "    X_regex = csr_matrix(regex_features_df.values)\n",
        "\n",
        "    # Combinando as duas matrizes de features horizontalmente para ter um único X\n",
        "    X_combined = hstack([X_tfidf, X_regex])\n",
        "\n",
        "    print(f\"\\nFormato da matriz TF-IDF: {X_tfidf.shape}\")\n",
        "    print(f\"Formato da matriz de Regex: {X_regex.shape}\")\n",
        "    print(f\"Formato da matriz Combinada: {X_combined.shape}\")\n"
      ],
      "metadata": {
        "id": "deapnnak1K43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Divisão treino/teste\n",
        "Usaremos 80% dos processos para treino e 20% para teste, garantindo que nenhum documento de mesmo processo caia em ambos os conjuntos.\n"
      ],
      "metadata": {
        "id": "PSWjgzT_1qV3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    test_size = 0.20 # tamanho do conjunto de teste\n",
        "    seed = 7 # semente aleatória\n",
        "\n",
        "    if len(np.unique(y)) < 2:\n",
        "        print(\"\\nErro: O dataset contém apenas uma classe após a extração e pré-processamento. Não é possível dividir em treino/teste com estratificação.\")\n",
        "    else:\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X_combined, y,\n",
        "            test_size=test_size, shuffle=True, random_state=seed, stratify=y) # holdout com estratificação\n",
        "\n",
        "## Parâmetros e partições da validação cruzada\n",
        "    scoring = 'accuracy'\n",
        "    num_particoes = 10\n",
        "    kfold = StratifiedKFold(n_splits=num_particoes, shuffle=True, random_state=seed) # crossvalidation com estratificação\n"
      ],
      "metadata": {
        "id": "F51DA-Ah1zRm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Treinamento dos algoritmos clássicos\n",
        "\n",
        "Aqui testaremos quatro algoritmos: Naive Bayes, SVM, Árvore de Decisão e KNN,\n",
        "observando suas particularidades para classificação de texto."
      ],
      "metadata": {
        "id": "xBzEs-KB19qK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(7) # definindo uma semente global\n",
        "\n",
        "    # Lista que armazenará os modelos\n",
        "    models = []\n",
        "\n",
        "    # Criando os modelos e adicionando-os na lista de modelos\n",
        "        models.append(('KNN', KNeighborsClassifier()))\n",
        "        models.append(('CART', DecisionTreeClassifier()))\n",
        "        # GaussianNB requires dense data, convert X_train if needed within the loop\n",
        "        models.append(('NB', GaussianNB()))\n",
        "        # LinearSVC is generally better for text classification than SVC\n",
        "        models.append(('SVM', LinearSVC(random_state=seed)))\n",
        "\n",
        "        # Listas para armazenar os resultados\n",
        "        results = []\n",
        "        names = []\n",
        "        scoring_results = [] # To store results for analysis and export"
      ],
      "metadata": {
        "id": "XGjkGWR226s9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Avaliação e comparação dos modelos"
      ],
      "metadata": {
        "id": "mHXfgvjt3H8T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nAvaliando modelos...\")\n",
        "        for name, model in models:\n",
        "            try:\n",
        "                if isinstance(model, GaussianNB):\n",
        "                     # Converte para array denso se for GaussianNB\n",
        "                     cv_results = cross_val_score(model, X_train.toarray(), y_train, cv=kfold, scoring=scoring)\n",
        "                else:\n",
        "                    cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n",
        "\n",
        "                results.append(cv_results)\n",
        "                names.append(name)\n",
        "                msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
        "                print(msg)\n",
        "                scoring_results.append({'Algoritmo': name, 'Mean Accuracy': cv_results.mean(), 'Std Dev Accuracy': cv_results.std()})\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Erro ao avaliar o modelo {name}: {e}\")\n",
        "                # Não pare a execução se um modelo falhar, apenas imprima o error\n",
        "                continue\n",
        "\n",
        "    # Boxplot de comparação dos modelos\n",
        "        if results: # Só tenta plotar se houver resultados\n",
        "            fig = plt.figure(figsize=(15,10))\n",
        "            fig.suptitle('Comparação dos Modelos')\n",
        "            ax = fig.add_subplot(111)\n",
        "            plt.boxplot(results)\n",
        "            ax.set_xticklabels(names)\n",
        "            plt.show()\n",
        "        else:\n",
        "            print(\"\\nNenhum resultado de modelo para plotar.\")\n",
        "\n",
        "        print(\"\\nAnálise dos resultados: (Este é um placeholder. Analise os resultados acima para descrever o desempenho de cada modelo aqui.)\")\n",
        "\n",
        "## Avaliação do melhor modelo com base nos testes\n",
        "        print(\"\\nAvaliação do modelo com o conjunto de testes\")\n",
        "\n",
        "## Determinando o melhor modelo com base nos resultados de cross-validation\n",
        "        if scoring_results:\n",
        "            results_df = pd.DataFrame(scoring_results)\n",
        "            # Lidando com dataframe vazio em caso de falhas\n",
        "            if not results_df.empty:\n",
        "                best_model_name = results_df.loc[results_df['Mean Accuracy'].idxmax(), 'Algoritmo']\n",
        "                print(f\"\\nMelhor modelo baseado na acurácia média da validação cruzada: {best_model_name}\")\n",
        "\n",
        "## Retreinando o melhor modelo com toda a base de dados de treino para garantir\n",
        "## o melhor resultado ao exportar os arquivos .pkl\n",
        "\n",
        "                best_model = None\n",
        "                if best_model_name == 'KNN':\n",
        "                    best_model = KNeighborsClassifier()\n",
        "                elif best_model_name == 'CART':\n",
        "                    best_model = DecisionTreeClassifier(random_state=seed)\n",
        "                elif best_model_name == 'NB':\n",
        "                     best_model = GaussianNB()\n",
        "                elif best_model_name == 'SVM':\n",
        "                    best_model = LinearSVC(random_state=seed) # Use LinearSVC for text\n",
        "\n",
        "                if best_model:\n",
        "                    try:\n",
        "                        if isinstance(best_model, GaussianNB):\n",
        "                             best_model.fit(X_train.toarray(), y_train)\n",
        "                             predictions = best_model.predict(X_test.toarray())\n",
        "                        else:\n",
        "                            best_model.fit(X_train, y_train)\n",
        "                            predictions = best_model.predict(X_test)\n",
        "\n",
        "                        print(\"\\nAvaliação no conjunto de teste:\")\n",
        "                        print(\"Accuracy:\", accuracy_score(y_test, predictions))\n",
        "                        print(\"F1-score:\", f1_score(y_test, predictions))\n",
        "                        print(\"\\nClassification Report:\\n\", classification_report(y_test, predictions))\n",
        "                        print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, predictions))"
      ],
      "metadata": {
        "id": "NdCdEIdp3WGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exportação do modelo vencedor"
      ],
      "metadata": {
        "id": "intDrfN-39en"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Salvamos o melhor modelo como arquivo .pkl, pronto para integração com a aplicação web.\n",
        "\n",
        "                        print(f\"\\nExportando o modelo vencedor: {best_model_name}\")\n",
        "                        joblib.dump(best_model, 'modelo_peticao_inicial.pkl')\n",
        "                        joblib.dump(vectorizer, 'vectorizer_peticao.pkl')\n",
        "                        print(\"Modelo e Vectorizer exportados com sucesso.\")"
      ],
      "metadata": {
        "id": "4omSIN7L4AQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Teste automatizado do modelo\n",
        "\n",
        "Implementei aqui o teste automatizado para assegurar que o modelo atenda aos requisitos de desempenho estabelecidos. Não fiz no backend porque ele é muito simples e a falta de persistência dos dados faz com que não seja possível testar naquele ambiente. No backend eu fiz um teste de validação da precisão distinto, que pode ser conferido no documento test_api.py lá. Aqui cumpri o requisito de ter um teste automatizado para assegurar que o modelo atenda aos requisitos de desempenho estabelecidos. A métrica se baseou no problema real, em que o usuário chega a errar 30% ou mais da classificação dos documentos no sistema PJe. Assim, o teste foi criado para garantir que o modelo só seja aceito se atingir um F1-score mínimo pré-definido de 75%, que justificaria seu uso em correção ao que faz o usuário atualmente de forma manual."
      ],
      "metadata": {
        "id": "CF185yrv4H7I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "                        print(\"\\nExecutando teste automatizado do modelo vencedor...\")\n",
        "                        def test_model_performance(model, X_test, y_test, threshold=0.75):\n",
        "                            from sklearn.metrics import f1_score\n",
        "                            # Regra especial para o tratamento do GaussianNB\n",
        "                            if isinstance(model, GaussianNB):\n",
        "                                y_pred = model.predict(X_test.toarray())\n",
        "                            else:\n",
        "                                y_pred = model.predict(X_test)\n",
        "                            f1 = f1_score(y_test, y_pred)\n",
        "                            assert f1 >= threshold, f\"F1-score abaixo do esperado: {f1:.2f} (esperado >= {threshold:.2f})\"\n",
        "                            print(f\"Teste automatizado passou: F1-score = {f1:.2f}\")\n",
        "\n",
        "                        try:\n",
        "                            # Use o modelo vencedor e os dados de teste\n",
        "                            test_model_performance(best_model, X_test, y_test, threshold=0.75)\n",
        "                        except AssertionError as e:\n",
        "                            print(f\"Teste automatizado falhou: {e}\")\n",
        "                        except Exception as e:\n",
        "                            print(f\"Ocorreu um erro durante o teste automatizado: {e}\")\n",
        "\n",
        "                    except Exception as e:\n",
        "                        print(f\"Erro ao treinar ou avaliar o melhor modelo ({best_model_name}) no conjunto de teste: {e}\")\n",
        "                        traceback.print_exc()\n",
        "                else:\n",
        "                     print(\"\\nNão foi possível encontrar o objeto do melhor modelo para exportação.\")\n",
        "\n",
        "            else:\n",
        "                 print(\"\\nNão há resultados de modelos para determinar o melhor modelo.\")\n",
        "        else:\n",
        "            print(\"\\nNenhum modelo foi avaliado com sucesso.\")\n",
        "\n",
        "else:\n",
        "    print(\"\\nDataFrame está vazio. Não é possível prosseguir com pré-processamento, treino e avaliação.\")\n"
      ],
      "metadata": {
        "id": "kOPVdwoY6AJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Análise dos resultados\n",
        "\n",
        "Os resultados mostram que o algoritmo de Árvore de Decisão obteve o melhor desempenho, oscilando entre 95% a 100% de acertos nos testes. No pior cenário, ele acertou 80% das petições iniciais que identificou, apontando 1 falso positivo.\n",
        "O resultado foi bastante destacado, mesmo em se considerando que todos os modelos foram muito bem. O resultado de alto acerto tem certamente relação com a combinação com Regex e os sinais fortes, mas não pode ser atribuído só a isso, considerando-se o próprio destaque do modelo de árvore de decisão sobre os demais.\n",
        "O motivo principal do sucesso tem relação com o problema, uma vez que os modelos de árvore de decisão são conhecidos por funcionarem bem em contextos jurídicos, em especial classificações como essa e o uso de Árvores de Classificação, quando o modelo tem que decidir se algo tem a caractertística de determinada classe ou não e seguir para a próxima bifurcação de decisão.\n",
        "A combinação de precião na decisão de um atributo com os sinais positivos de Regex ainda potencializou mais este modelo que os demais."
      ],
      "metadata": {
        "id": "LteuwHNr6Egl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusão\n",
        "\n",
        "Neste notebook, mostrei todo o pipeline de identificação automática de Petições Iniciais, comentando o problema e a forma de sua solução que encontrei aqui. Ao longo do notebook, foi possível encontrar tudo que foi pedido no exercício, incluindo pré-processamento, normalização dos dados, otimização de parâmetros, avaliação de algoritmos clássicos, escolha do modelo vencedor e preparação para integração full stack. A isso, some-se o esforço de também entregar o backend e o front-end para integrar a aplicação full stack.\n",
        "Por fim, quanto ao problema em si, o resultado geral e próximos passos, entendo que parte dos motivos de um resultado tão positivo tem a ver com o tamanho enxuto da base de dados. Gostaria de, no futuro, submetê-lo a uma base maior (que eu até tenho aqui classificada, mas sem o mesmo rigor dessa base ouro usada aqui).\n",
        "Entendo que, em especial o pkl combinado aqui deste notebook pode ser realmente útil em trabalhos reais no futuro. Antes disso, todavia, quero estressar mais os 4 modelos, em especial o CART, para ver se esse resultado excelente se repete em vários cenários. Em caso positivo, é possível que uma grande quantidade de processos judiciais reais tenham os dados que os identificam finalmente corrigidos nos bancos de dados do Judiciário, viabilizando uma série de melhorias de longo prazo para aqueles que mais precisam da Justiça."
      ],
      "metadata": {
        "id": "uo-ke2d064ef"
      }
    }
  ]
}